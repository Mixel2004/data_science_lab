{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Neural Network from scratch </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Each row is a training example, each column is a feature  [f1, f2, f3]\n",
    "X=[0,0,1],[0,1,1],[1,0,1],[1,1,1]\n",
    "y=[0],[1],[1],[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing x and y with numpy\n",
    "import numpy as np\n",
    "X=np.array(([0,0,1],[0,1,1],[1,0,1],[1,1,1]), dtype=float)\n",
    "y=np.array(([0],[1],[1],[0]), dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Activation Function </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid  function\n",
    "def sigmoid(t):\n",
    "    '''This will return the sigmoid value of the function'''\n",
    "    return 1/(1+np.exp(-t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derivative sigmoid\n",
    "def sigmoid_derivative(d):\n",
    "    return d * (1 - d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class definition\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, x,y):\n",
    "        self.input = x #initializing x\n",
    "        self.weights1= np.random.rand(self.input.shape[1],4) #initializing random weights\n",
    "        self.weights2 = np.random.rand(4,1)#considering we have 4 nodes in the hidden layer\n",
    "        self.y = y#initializing y\n",
    "        self.output = np. zeros(y.shape)#initializing the output\n",
    "        \n",
    "    def feedforward(self):\n",
    "        '''This will perform the forward propagation for the next 2 layers'''\n",
    "        self.layer1 = sigmoid(np.dot(self.input, self.weights1))#calcuation of w_T*X+b for layer1\n",
    "        self.layer2 = sigmoid(np.dot(self.layer1, self.weights2))#calcuation of w_T*X+b for layer2\n",
    "        return self.layer2\n",
    "        \n",
    "    def backprop(self):\n",
    "        '''Back propagation of the final hidden layers to initial layers'''\n",
    "        derv_weights2 = np.dot(self.layer1.T, 2*(self.y -self.output)*sigmoid_derivative(self.output))#backpropagation of layer2\n",
    "        derv_weights1 = np.dot(self.input.T, np.dot(2*(self.y -self.output)*sigmoid_derivative(self.output), self.weights2.T)*sigmoid_derivative(self.layer1))\n",
    "    \n",
    "        self.weights1 += derv_weights1#updation of weight matrix of layer1\n",
    "        self.weights2 += derv_weights2#updation of weight matrix of layer2\n",
    "\n",
    "    def train(self, X, y):\n",
    "        self.output = self.feedforward()#Forward Propagation\n",
    "        self.backprop()#Backward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for iteration # 0\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.76868307]\n",
      " [0.81237504]\n",
      " [0.82459718]\n",
      " [0.84949885]]\n",
      "Loss: \n",
      "0.3446228065861043\n",
      "\n",
      "\n",
      "for iteration # 100\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.43395583]\n",
      " [0.50937429]\n",
      " [0.56412634]\n",
      " [0.54347193]]\n",
      "Loss: \n",
      "0.22859470746812943\n",
      "\n",
      "\n",
      "for iteration # 200\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.1334758 ]\n",
      " [0.76519795]\n",
      " [0.797467  ]\n",
      " [0.27590678]]\n",
      "Loss: \n",
      "0.047522989932560364\n",
      "\n",
      "\n",
      "for iteration # 300\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.05235337]\n",
      " [0.89205719]\n",
      " [0.90042358]\n",
      " [0.12878033]]\n",
      "Loss: \n",
      "0.010223090899629264\n",
      "\n",
      "\n",
      "for iteration # 400\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.03415193]\n",
      " [0.92378535]\n",
      " [0.92858153]\n",
      " [0.09151756]]\n",
      "Loss: \n",
      "0.005112772349323401\n",
      "\n",
      "\n",
      "for iteration # 500\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.02619693]\n",
      " [0.93860028]\n",
      " [0.94201021]\n",
      " [0.07400068]]\n",
      "Loss: \n",
      "0.0033237803189211735\n",
      "\n",
      "\n",
      "for iteration # 600\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.02165361]\n",
      " [0.94744087]\n",
      " [0.95011187]\n",
      " [0.0635039 ]]\n",
      "Loss: \n",
      "0.0024382280372121723\n",
      "\n",
      "\n",
      "for iteration # 700\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.01867511]\n",
      " [0.95342863]\n",
      " [0.95563848]\n",
      " [0.05637313]]\n",
      "Loss: \n",
      "0.0019158815976767795\n",
      "\n",
      "\n",
      "for iteration # 800\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.01655166]\n",
      " [0.95780928]\n",
      " [0.95970279]\n",
      " [0.05114424]]\n",
      "Loss: \n",
      "0.0015734032110067452\n",
      "\n",
      "\n",
      "for iteration # 900\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.0149501 ]\n",
      " [0.96118468]\n",
      " [0.96284702]\n",
      " [0.0471078 ]]\n",
      "Loss: \n",
      "0.0013324059042794096\n",
      "\n",
      "\n",
      "for iteration # 1000\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.01369238]\n",
      " [0.96388409]\n",
      " [0.96536971]\n",
      " [0.04387478]]\n",
      "Loss: \n",
      "0.0011540234911655183\n",
      "\n",
      "\n",
      "for iteration # 1100\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.01267423]\n",
      " [0.96610415]\n",
      " [0.96745002]\n",
      " [0.04121237]]\n",
      "Loss: \n",
      "0.001016881487397807\n",
      "\n",
      "\n",
      "for iteration # 1200\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.0118303 ]\n",
      " [0.96797024]\n",
      " [0.96920263]\n",
      " [0.03897193]]\n",
      "Loss: \n",
      "0.0009082876113179696\n",
      "\n",
      "\n",
      "for iteration # 1300\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.0111174 ]\n",
      " [0.96956643]\n",
      " [0.97070473]\n",
      " [0.03705362]]\n",
      "Loss: \n",
      "0.0008202456285066064\n",
      "\n",
      "\n",
      "for iteration # 1400\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.01050578]\n",
      " [0.97095142]\n",
      " [0.97201033]\n",
      " [0.03538766]]\n",
      "Loss: \n",
      "0.0007474750416417242\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=NeuralNetwork(X,y)\n",
    "for i in range(1500):\n",
    "    if i % 100 ==0:#For each 100 epochs output will come \n",
    "        print (\"for iteration # \" + str(i) + \"\\n\")\n",
    "        print (\"Input : \\n\" + str(X))\n",
    "        print (\"Actual Output: \\n\" + str(y))\n",
    "        print (\"Predicted Output: \\n\" + str(model.feedforward()))\n",
    "        print (\"Loss: \\n\" + str(np.mean(np.square(y - model.feedforward())))) # mean sum squared loss\n",
    "        print (\"\\n\")\n",
    "  \n",
    "    model.train(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
