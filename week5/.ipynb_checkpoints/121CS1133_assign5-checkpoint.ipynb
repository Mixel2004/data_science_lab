{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Laptop\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet = pd.read_csv('DelhiAQI.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    PM2.5    PM10      NO    NO2     NOx    NH3     CO   SO2     O3  Benzene  \\\n",
      "0  454.58  935.18   81.52  41.78  187.66  27.54   9.29  3.41  54.94    25.24   \n",
      "1  440.44  935.18   70.80  43.46  176.83  27.72  13.28  3.88  50.53    23.10   \n",
      "2  409.09  935.18  132.46  41.19  141.02  28.94  29.67  2.83  19.33    19.04   \n",
      "3  436.12  935.18   84.78  39.55  102.84  29.30  21.76  4.33  20.08    13.99   \n",
      "4  415.88  976.99   60.24  37.41   80.12  30.84  26.19  6.17  16.00    11.14   \n",
      "\n",
      "   Toluene  Xylene  AQI  \n",
      "0    58.57   13.80  653  \n",
      "1    49.37   15.63  645  \n",
      "2    38.94   17.18  532  \n",
      "3    27.53   16.82  561  \n",
      "4    21.99   14.29  567  \n",
      "(15000, 13)\n"
     ]
    }
   ],
   "source": [
    "print(dataSet.head())\n",
    "print(dataSet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the data\n",
    "dataSetNorm1 = dataSet.dropna()\n",
    "for i in dataSetNorm1.columns:\n",
    "    if i != 'AQI':\n",
    "        # use the median and std of the training data to normalize (Z-score scaling)\n",
    "        dataSetNorm1[i] = (dataSetNorm1[i] - dataSetNorm1[i].mean()) / dataSetNorm1[i].std()\n",
    "\n",
    "X = dataSetNorm1.drop('AQI', axis=1)\n",
    "y = dataSetNorm1['AQI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 12386.1943 - val_loss: 3169.8613\n",
      "Epoch 2/20\n",
      "563/563 [==============================] - 1s 989us/step - loss: 3224.3071 - val_loss: 3002.4209\n",
      "Epoch 3/20\n",
      "563/563 [==============================] - 1s 1000us/step - loss: 3121.0959 - val_loss: 3019.6687\n",
      "Epoch 4/20\n",
      "563/563 [==============================] - 1s 958us/step - loss: 3042.1355 - val_loss: 2909.5486\n",
      "Epoch 5/20\n",
      "563/563 [==============================] - 1s 933us/step - loss: 2996.9778 - val_loss: 2874.4570\n",
      "Epoch 6/20\n",
      "563/563 [==============================] - 1s 942us/step - loss: 2964.1426 - val_loss: 2827.1260\n",
      "Epoch 7/20\n",
      "563/563 [==============================] - 1s 931us/step - loss: 2923.3037 - val_loss: 2841.1707\n",
      "Epoch 8/20\n",
      "563/563 [==============================] - 1s 929us/step - loss: 2882.3889 - val_loss: 2938.6287\n",
      "Epoch 9/20\n",
      "563/563 [==============================] - 1s 928us/step - loss: 2852.2292 - val_loss: 2818.6968\n",
      "Epoch 10/20\n",
      "563/563 [==============================] - 1s 938us/step - loss: 2832.3335 - val_loss: 2849.4070\n",
      "Epoch 11/20\n",
      "563/563 [==============================] - 1s 920us/step - loss: 2799.4294 - val_loss: 2806.5847\n",
      "Epoch 12/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2781.4626 - val_loss: 2743.4207\n",
      "Epoch 13/20\n",
      "563/563 [==============================] - 1s 978us/step - loss: 2775.0447 - val_loss: 2695.7910\n",
      "Epoch 14/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2742.0383 - val_loss: 2697.2566\n",
      "Epoch 15/20\n",
      "563/563 [==============================] - 1s 962us/step - loss: 2717.8757 - val_loss: 2696.4504\n",
      "Epoch 16/20\n",
      "563/563 [==============================] - 1s 959us/step - loss: 2704.7046 - val_loss: 2701.8970\n",
      "Epoch 17/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2690.1560 - val_loss: 2694.3113\n",
      "Epoch 18/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2683.0188 - val_loss: 2702.7073\n",
      "Epoch 19/20\n",
      "563/563 [==============================] - 1s 958us/step - loss: 2664.4465 - val_loss: 2636.5217\n",
      "Epoch 20/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2670.7173 - val_loss: 2641.7043\n",
      "94/94 [==============================] - 0s 635us/step\n",
      "Model: 1\n",
      "Mean Squared Error: 2833.144\n",
      "--------------------\n",
      "Epoch 1/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 67720.2734 - val_loss: 3391.4583\n",
      "Epoch 2/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 3262.6853 - val_loss: 2996.0957\n",
      "Epoch 3/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 3069.9128 - val_loss: 2915.0986\n",
      "Epoch 4/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2990.0513 - val_loss: 2872.5991\n",
      "Epoch 5/20\n",
      "563/563 [==============================] - 1s 978us/step - loss: 2941.7473 - val_loss: 2864.8022\n",
      "Epoch 6/20\n",
      "563/563 [==============================] - 1s 970us/step - loss: 2909.7000 - val_loss: 2920.1394\n",
      "Epoch 7/20\n",
      "563/563 [==============================] - 1s 966us/step - loss: 2860.5850 - val_loss: 2788.0869\n",
      "Epoch 8/20\n",
      "563/563 [==============================] - 1s 970us/step - loss: 2834.9961 - val_loss: 2758.7078\n",
      "Epoch 9/20\n",
      "563/563 [==============================] - 1s 966us/step - loss: 2812.9812 - val_loss: 2720.4287\n",
      "Epoch 10/20\n",
      "563/563 [==============================] - 1s 971us/step - loss: 2780.8284 - val_loss: 2730.7773\n",
      "Epoch 11/20\n",
      "563/563 [==============================] - 1s 974us/step - loss: 2765.2202 - val_loss: 2701.7969\n",
      "Epoch 12/20\n",
      "563/563 [==============================] - 1s 971us/step - loss: 2750.9094 - val_loss: 2755.0935\n",
      "Epoch 13/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2718.2415 - val_loss: 2686.9539\n",
      "Epoch 14/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2709.6721 - val_loss: 2683.2146\n",
      "Epoch 15/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2698.4006 - val_loss: 2669.4521\n",
      "Epoch 16/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2677.9604 - val_loss: 2667.4136\n",
      "Epoch 17/20\n",
      "563/563 [==============================] - 1s 997us/step - loss: 2664.0356 - val_loss: 2709.9001\n",
      "Epoch 18/20\n",
      "563/563 [==============================] - 1s 982us/step - loss: 2649.8252 - val_loss: 2634.8906\n",
      "Epoch 19/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2646.6160 - val_loss: 2665.9331\n",
      "Epoch 20/20\n",
      "563/563 [==============================] - 1s 980us/step - loss: 2628.5146 - val_loss: 2661.7500\n",
      "94/94 [==============================] - 0s 617us/step\n",
      "Model: 2\n",
      "Mean Squared Error: 2813.283\n",
      "--------------------\n",
      "Epoch 1/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 15177.6982 - val_loss: 3304.3887\n",
      "Epoch 2/20\n",
      "563/563 [==============================] - 1s 996us/step - loss: 3271.4614 - val_loss: 3072.2812\n",
      "Epoch 3/20\n",
      "563/563 [==============================] - 1s 974us/step - loss: 3138.5293 - val_loss: 2991.6814\n",
      "Epoch 4/20\n",
      "563/563 [==============================] - 1s 985us/step - loss: 3077.4502 - val_loss: 3094.5723\n",
      "Epoch 5/20\n",
      "563/563 [==============================] - 1s 952us/step - loss: 3021.9497 - val_loss: 2924.0828\n",
      "Epoch 6/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2969.6064 - val_loss: 2853.2686\n",
      "Epoch 7/20\n",
      "563/563 [==============================] - 1s 956us/step - loss: 2934.2266 - val_loss: 2839.5742\n",
      "Epoch 8/20\n",
      "563/563 [==============================] - 1s 988us/step - loss: 2902.6880 - val_loss: 2874.7520\n",
      "Epoch 9/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2870.2756 - val_loss: 2788.4583\n",
      "Epoch 10/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2833.4463 - val_loss: 2783.4084\n",
      "Epoch 11/20\n",
      "563/563 [==============================] - 1s 998us/step - loss: 2817.7791 - val_loss: 2750.9062\n",
      "Epoch 12/20\n",
      "563/563 [==============================] - 1s 999us/step - loss: 2791.2935 - val_loss: 2744.0894\n",
      "Epoch 13/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2776.0776 - val_loss: 2686.3794\n",
      "Epoch 14/20\n",
      "563/563 [==============================] - 1s 960us/step - loss: 2746.2339 - val_loss: 2744.6260\n",
      "Epoch 15/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2726.1538 - val_loss: 2665.9426\n",
      "Epoch 16/20\n",
      "563/563 [==============================] - 1s 966us/step - loss: 2716.7556 - val_loss: 2649.8630\n",
      "Epoch 17/20\n",
      "563/563 [==============================] - 1s 982us/step - loss: 2701.9670 - val_loss: 2684.5811\n",
      "Epoch 18/20\n",
      "563/563 [==============================] - 1s 978us/step - loss: 2687.2585 - val_loss: 2667.4841\n",
      "Epoch 19/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2681.6436 - val_loss: 2622.9536\n",
      "Epoch 20/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2660.3882 - val_loss: 2634.6270\n",
      "94/94 [==============================] - 0s 650us/step\n",
      "Model: 3\n",
      "Mean Squared Error: 2827.5693333333334\n",
      "--------------------\n",
      "Epoch 1/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 12271.5635 - val_loss: 3130.0537\n",
      "Epoch 2/20\n",
      "563/563 [==============================] - 1s 963us/step - loss: 3206.3442 - val_loss: 3217.1248\n",
      "Epoch 3/20\n",
      "563/563 [==============================] - 1s 959us/step - loss: 3124.7283 - val_loss: 2996.3950\n",
      "Epoch 4/20\n",
      "563/563 [==============================] - 1s 978us/step - loss: 3056.3398 - val_loss: 2906.5532\n",
      "Epoch 5/20\n",
      "563/563 [==============================] - 1s 957us/step - loss: 3023.7029 - val_loss: 2919.6509\n",
      "Epoch 6/20\n",
      "563/563 [==============================] - 1s 962us/step - loss: 2961.8660 - val_loss: 2891.7434\n",
      "Epoch 7/20\n",
      "563/563 [==============================] - 1s 996us/step - loss: 2934.0178 - val_loss: 2827.2297\n",
      "Epoch 8/20\n",
      "563/563 [==============================] - 1s 974us/step - loss: 2881.8179 - val_loss: 2803.2207\n",
      "Epoch 9/20\n",
      "563/563 [==============================] - 1s 973us/step - loss: 2863.6665 - val_loss: 2754.5618\n",
      "Epoch 10/20\n",
      "563/563 [==============================] - 1s 967us/step - loss: 2831.6968 - val_loss: 2738.8167\n",
      "Epoch 11/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2793.0251 - val_loss: 2771.6121\n",
      "Epoch 12/20\n",
      "563/563 [==============================] - 1s 964us/step - loss: 2777.6580 - val_loss: 2695.4036\n",
      "Epoch 13/20\n",
      "563/563 [==============================] - 1s 956us/step - loss: 2744.1897 - val_loss: 2663.1221\n",
      "Epoch 14/20\n",
      "563/563 [==============================] - 1s 965us/step - loss: 2725.2126 - val_loss: 2667.6621\n",
      "Epoch 15/20\n",
      "563/563 [==============================] - 1s 957us/step - loss: 2724.0776 - val_loss: 2693.4387\n",
      "Epoch 16/20\n",
      "563/563 [==============================] - 1s 963us/step - loss: 2686.2009 - val_loss: 2651.6179\n",
      "Epoch 17/20\n",
      "563/563 [==============================] - 1s 998us/step - loss: 2684.8845 - val_loss: 2659.5645\n",
      "Epoch 18/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2659.0603 - val_loss: 2636.0557\n",
      "Epoch 19/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2654.8752 - val_loss: 2613.6868\n",
      "Epoch 20/20\n",
      "563/563 [==============================] - 1s 989us/step - loss: 2654.6929 - val_loss: 2595.0212\n",
      "94/94 [==============================] - 0s 675us/step\n",
      "Model: 4\n",
      "Mean Squared Error: 2814.11\n",
      "--------------------\n",
      "Epoch 1/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 10612.2402 - val_loss: 3144.6516\n",
      "Epoch 2/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 3183.3821 - val_loss: 2995.6023\n",
      "Epoch 3/20\n",
      "563/563 [==============================] - 1s 977us/step - loss: 3091.5159 - val_loss: 2953.8066\n",
      "Epoch 4/20\n",
      "563/563 [==============================] - 1s 981us/step - loss: 3027.6396 - val_loss: 2932.8113\n",
      "Epoch 5/20\n",
      "563/563 [==============================] - 1s 968us/step - loss: 2986.3689 - val_loss: 2826.3479\n",
      "Epoch 6/20\n",
      "563/563 [==============================] - 1s 978us/step - loss: 2958.3760 - val_loss: 3035.8328\n",
      "Epoch 7/20\n",
      "563/563 [==============================] - 1s 981us/step - loss: 2916.1821 - val_loss: 2785.8027\n",
      "Epoch 8/20\n",
      "563/563 [==============================] - 1s 967us/step - loss: 2866.9260 - val_loss: 2828.3806\n",
      "Epoch 9/20\n",
      "563/563 [==============================] - 1s 961us/step - loss: 2861.6650 - val_loss: 2748.5144\n",
      "Epoch 10/20\n",
      "563/563 [==============================] - 1s 971us/step - loss: 2812.2842 - val_loss: 2772.7317\n",
      "Epoch 11/20\n",
      "563/563 [==============================] - 1s 972us/step - loss: 2798.4849 - val_loss: 2740.9192\n",
      "Epoch 12/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2784.7004 - val_loss: 2731.5090\n",
      "Epoch 13/20\n",
      "563/563 [==============================] - 1s 961us/step - loss: 2743.0798 - val_loss: 2751.8921\n",
      "Epoch 14/20\n",
      "563/563 [==============================] - 1s 982us/step - loss: 2731.4741 - val_loss: 2642.9124\n",
      "Epoch 15/20\n",
      "563/563 [==============================] - 1s 954us/step - loss: 2694.9863 - val_loss: 2636.0046\n",
      "Epoch 16/20\n",
      "563/563 [==============================] - 1s 975us/step - loss: 2684.0081 - val_loss: 2669.4751\n",
      "Epoch 17/20\n",
      "563/563 [==============================] - 1s 954us/step - loss: 2679.3677 - val_loss: 2659.5439\n",
      "Epoch 18/20\n",
      "563/563 [==============================] - 1s 973us/step - loss: 2657.2859 - val_loss: 2629.3364\n",
      "Epoch 19/20\n",
      "563/563 [==============================] - 1s 957us/step - loss: 2641.1350 - val_loss: 2617.2151\n",
      "Epoch 20/20\n",
      "563/563 [==============================] - 1s 960us/step - loss: 2634.3306 - val_loss: 2633.6499\n",
      "94/94 [==============================] - 0s 614us/step\n",
      "Model: 5\n",
      "Mean Squared Error: 2828.3056666666666\n",
      "--------------------\n",
      "Average Mean Squared Error: 2823.2824\n"
     ]
    }
   ],
   "source": [
    "# Implement deep multilayer perceptron neural network Model-I : Add a fully connected layer with 32 neurons with sigmoid activation\n",
    "# and glorot uniform kernel initializer. Add a fully connected layer layer with 16\n",
    "# neurons, relu activation and he uniform as kernel initializer. Add a fully\n",
    "# connected layer with 1 neuron, relu activation function and he uniform as\n",
    "# kernel initializer. Use Adam optimizer with batch size 16, learning rate 0.01\n",
    "# and epochs set to 20.\n",
    "# Test using root mean squared error as loss function.\n",
    "\n",
    "def model1(X_train, X_val, y_train, y_val):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, activation='sigmoid', kernel_initializer='glorot_uniform'))\n",
    "    model.add(Dense(16, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(1, activation='relu', kernel_initializer='he_uniform'))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.01), loss='mean_squared_error', batch_size=16, epochs=20)\n",
    "\n",
    "    model.fit(X_train, y_train,  validation_data=(X_val, y_val))\n",
    "    \n",
    "    return model\n",
    "\n",
    "count = 5\n",
    "avg_mse = 0\n",
    "for i in range(count):\n",
    "    # Split data to 60% training 20% validation and 20% testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "    model = model1(X_train, X_val, y_train, y_val)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print('Model:', i+1)\n",
    "    y_pred = np.round(y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print('Mean Squared Error:', mse)\n",
    "    print(\"--------------------\")\n",
    "    avg_mse += mse\n",
    "\n",
    "print('Average Mean Squared Error:', avg_mse/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1125/1125 [==============================] - 2s 996us/step - loss: 88622.5859 - val_loss: 87336.4844\n",
      "Epoch 2/20\n",
      "1125/1125 [==============================] - 1s 958us/step - loss: 88622.5703 - val_loss: 87336.4844\n",
      "Epoch 3/20\n",
      "1125/1125 [==============================] - 1s 940us/step - loss: 88622.5469 - val_loss: 87336.4844\n",
      "Epoch 4/20\n",
      "1125/1125 [==============================] - 1s 921us/step - loss: 88622.5781 - val_loss: 87336.4844\n",
      "Epoch 5/20\n",
      "1125/1125 [==============================] - 1s 945us/step - loss: 88622.5859 - val_loss: 87336.4844\n",
      "Epoch 6/20\n",
      "1125/1125 [==============================] - 1s 935us/step - loss: 88622.5391 - val_loss: 87336.4844\n",
      "Epoch 7/20\n",
      "1125/1125 [==============================] - 1s 989us/step - loss: 88622.5547 - val_loss: 87336.4844\n",
      "Epoch 8/20\n",
      "1125/1125 [==============================] - 1s 964us/step - loss: 88622.6016 - val_loss: 87336.4844\n",
      "Epoch 9/20\n",
      "1125/1125 [==============================] - 1s 961us/step - loss: 88622.5391 - val_loss: 87336.4844\n",
      "Epoch 10/20\n",
      "1125/1125 [==============================] - 1s 965us/step - loss: 88622.5469 - val_loss: 87336.4844\n",
      "Epoch 11/20\n",
      "1125/1125 [==============================] - 1s 1ms/step - loss: 88622.5703 - val_loss: 87336.4844\n",
      "Epoch 12/20\n",
      "1125/1125 [==============================] - 1s 1ms/step - loss: 88622.5156 - val_loss: 87336.4844\n",
      "Epoch 13/20\n",
      "1125/1125 [==============================] - 1s 1ms/step - loss: 88622.5625 - val_loss: 87336.4844\n",
      "Epoch 14/20\n",
      "1125/1125 [==============================] - 1s 1ms/step - loss: 88622.4922 - val_loss: 87336.4844\n",
      "Epoch 15/20\n",
      "1125/1125 [==============================] - 1s 1ms/step - loss: 88622.6172 - val_loss: 87336.4844\n",
      "Epoch 16/20\n",
      "1125/1125 [==============================] - 1s 969us/step - loss: 88622.5078 - val_loss: 87336.4844\n",
      "Epoch 17/20\n",
      "1125/1125 [==============================] - 1s 945us/step - loss: 88622.6172 - val_loss: 87336.4844\n",
      "Epoch 18/20\n",
      "1125/1125 [==============================] - 1s 974us/step - loss: 88622.5625 - val_loss: 87336.4844\n",
      "Epoch 19/20\n",
      "1125/1125 [==============================] - 1s 919us/step - loss: 88622.5000 - val_loss: 87336.4844\n",
      "Epoch 20/20\n",
      "1125/1125 [==============================] - 1s 938us/step - loss: 88622.5312 - val_loss: 87336.4844\n",
      "282/282 [==============================] - 0s 572us/step\n",
      "94/94 [==============================] - 0s 611us/step\n",
      "Model: 1\n",
      "Mean Squared Error: 4731.069333333333\n",
      "--------------------\n",
      "Epoch 1/20\n",
      "1125/1125 [==============================] - 2s 985us/step - loss: 67297.6875 - val_loss: 46958.6758\n",
      "Epoch 2/20\n",
      "1125/1125 [==============================] - 1s 947us/step - loss: 35098.2461 - val_loss: 24068.2637\n",
      "Epoch 3/20\n",
      "1125/1125 [==============================] - 1s 1ms/step - loss: 18585.6934 - val_loss: 13300.7422\n",
      "Epoch 4/20\n",
      "1125/1125 [==============================] - 1s 1ms/step - loss: 10751.9238 - val_loss: 7595.8467\n",
      "Epoch 5/20\n",
      "1125/1125 [==============================] - 1s 958us/step - loss: 6486.3086 - val_loss: 5031.7549\n",
      "Epoch 6/20\n",
      "1125/1125 [==============================] - 1s 958us/step - loss: 4717.8071 - val_loss: 4021.4944\n",
      "Epoch 7/20\n",
      "1125/1125 [==============================] - 1s 929us/step - loss: 3983.1685 - val_loss: 3598.6252\n",
      "Epoch 8/20\n",
      "1125/1125 [==============================] - 1s 903us/step - loss: 3592.4619 - val_loss: 3362.4221\n",
      "Epoch 9/20\n",
      "1125/1125 [==============================] - 1s 940us/step - loss: 3402.0837 - val_loss: 3253.7393\n",
      "Epoch 10/20\n",
      "1125/1125 [==============================] - 1s 939us/step - loss: 3231.3818 - val_loss: 3097.0500\n",
      "Epoch 11/20\n",
      "1125/1125 [==============================] - 1s 915us/step - loss: 3097.4390 - val_loss: 3105.1289\n",
      "Epoch 12/20\n",
      "1125/1125 [==============================] - 1s 912us/step - loss: 3026.4004 - val_loss: 2992.4409\n",
      "Epoch 13/20\n",
      "1125/1125 [==============================] - 1s 936us/step - loss: 2948.9893 - val_loss: 2935.9104\n",
      "Epoch 14/20\n",
      "1125/1125 [==============================] - 1s 950us/step - loss: 2888.5703 - val_loss: 2862.7556\n",
      "Epoch 15/20\n",
      "1125/1125 [==============================] - 1s 964us/step - loss: 2812.3210 - val_loss: 2859.9844\n",
      "Epoch 16/20\n",
      "1125/1125 [==============================] - 1s 1ms/step - loss: 2764.9932 - val_loss: 2841.6377\n",
      "Epoch 17/20\n",
      "1125/1125 [==============================] - 1s 1ms/step - loss: 2704.1492 - val_loss: 2776.0459\n",
      "Epoch 18/20\n",
      "1125/1125 [==============================] - 1s 1ms/step - loss: 2671.3445 - val_loss: 2738.9321\n",
      "Epoch 19/20\n",
      "1125/1125 [==============================] - 1s 952us/step - loss: 2631.8655 - val_loss: 2724.4058\n",
      "Epoch 20/20\n",
      "1125/1125 [==============================] - 1s 960us/step - loss: 2617.8184 - val_loss: 2679.6694\n",
      "282/282 [==============================] - 0s 567us/step\n",
      "94/94 [==============================] - 0s 575us/step\n",
      "Model: 2\n",
      "Mean Squared Error: 2957.198\n",
      "--------------------\n",
      "Epoch 1/20\n",
      "1125/1125 [==============================] - 2s 1ms/step - loss: 67699.0625 - val_loss: 50201.3008\n",
      "Epoch 2/20\n",
      "1125/1125 [==============================] - 1s 916us/step - loss: 37512.6367 - val_loss: 25001.9492\n",
      "Epoch 3/20\n",
      "1125/1125 [==============================] - 1s 907us/step - loss: 19162.2539 - val_loss: 13616.2734\n",
      "Epoch 4/20\n",
      "1125/1125 [==============================] - 1s 915us/step - loss: 10853.2910 - val_loss: 7670.9629\n",
      "Epoch 5/20\n",
      "1125/1125 [==============================] - 1s 917us/step - loss: 6583.5645 - val_loss: 5105.7202\n",
      "Epoch 6/20\n",
      "1125/1125 [==============================] - 1s 932us/step - loss: 4750.0933 - val_loss: 4027.2471\n",
      "Epoch 7/20\n",
      "1125/1125 [==============================] - 1s 898us/step - loss: 3976.0081 - val_loss: 3605.2471\n",
      "Epoch 8/20\n",
      "1125/1125 [==============================] - 1s 913us/step - loss: 3547.5894 - val_loss: 3276.8850\n",
      "Epoch 9/20\n",
      "1125/1125 [==============================] - 1s 932us/step - loss: 3261.4717 - val_loss: 3120.7939\n",
      "Epoch 10/20\n",
      "1125/1125 [==============================] - 1s 955us/step - loss: 3071.2441 - val_loss: 3092.0896\n",
      "Epoch 11/20\n",
      "1125/1125 [==============================] - 1s 945us/step - loss: 2961.8394 - val_loss: 2914.6960\n",
      "Epoch 12/20\n",
      "1125/1125 [==============================] - 1s 889us/step - loss: 2874.2412 - val_loss: 2835.3433\n",
      "Epoch 13/20\n",
      "1125/1125 [==============================] - 1s 910us/step - loss: 2807.8359 - val_loss: 2873.0576\n",
      "Epoch 14/20\n",
      "1125/1125 [==============================] - 1s 947us/step - loss: 2765.4314 - val_loss: 2813.1252\n",
      "Epoch 15/20\n",
      "1125/1125 [==============================] - 1s 926us/step - loss: 2725.6604 - val_loss: 2767.7368\n",
      "Epoch 16/20\n",
      "1125/1125 [==============================] - 1s 934us/step - loss: 2680.7961 - val_loss: 2732.5759\n",
      "Epoch 17/20\n",
      "1125/1125 [==============================] - 1s 921us/step - loss: 2651.3953 - val_loss: 2759.2939\n",
      "Epoch 18/20\n",
      "1125/1125 [==============================] - 1s 946us/step - loss: 2629.0681 - val_loss: 2698.6003\n",
      "Epoch 19/20\n",
      "1125/1125 [==============================] - 1s 902us/step - loss: 2595.8362 - val_loss: 2675.0581\n",
      "Epoch 20/20\n",
      "1125/1125 [==============================] - 1s 923us/step - loss: 2570.0564 - val_loss: 2630.8638\n",
      "282/282 [==============================] - 0s 629us/step\n",
      "94/94 [==============================] - 0s 627us/step\n",
      "Model: 3\n",
      "Mean Squared Error: 2919.4283333333333\n",
      "--------------------\n",
      "Epoch 1/20\n",
      "1125/1125 [==============================] - 2s 989us/step - loss: 88622.5234 - val_loss: 87336.4844\n",
      "Epoch 2/20\n",
      "1125/1125 [==============================] - 1s 944us/step - loss: 88622.6094 - val_loss: 87336.4844\n",
      "Epoch 3/20\n",
      "1125/1125 [==============================] - 1s 923us/step - loss: 88622.5078 - val_loss: 87336.4844\n",
      "Epoch 4/20\n",
      "1125/1125 [==============================] - 1s 915us/step - loss: 88622.5312 - val_loss: 87336.4844\n",
      "Epoch 5/20\n",
      "1125/1125 [==============================] - 1s 952us/step - loss: 88622.5469 - val_loss: 87336.4844\n",
      "Epoch 6/20\n",
      "1125/1125 [==============================] - 1s 935us/step - loss: 88622.4922 - val_loss: 87336.4844\n",
      "Epoch 7/20\n",
      "1125/1125 [==============================] - 1s 913us/step - loss: 88622.4531 - val_loss: 87336.4844\n",
      "Epoch 8/20\n",
      "1125/1125 [==============================] - 1s 967us/step - loss: 88622.5625 - val_loss: 87336.4844\n",
      "Epoch 9/20\n",
      "1125/1125 [==============================] - 1s 936us/step - loss: 88622.5234 - val_loss: 87336.4844\n",
      "Epoch 10/20\n",
      "1125/1125 [==============================] - 1s 945us/step - loss: 88622.5391 - val_loss: 87336.4844\n",
      "Epoch 11/20\n",
      "1125/1125 [==============================] - 1s 917us/step - loss: 88622.5078 - val_loss: 87336.4844\n",
      "Epoch 12/20\n",
      "1125/1125 [==============================] - 1s 977us/step - loss: 88622.5391 - val_loss: 87336.4844\n",
      "Epoch 13/20\n",
      "1125/1125 [==============================] - 1s 987us/step - loss: 88622.4766 - val_loss: 87336.4844\n",
      "Epoch 14/20\n",
      "1125/1125 [==============================] - 1s 947us/step - loss: 88622.5938 - val_loss: 87336.4844\n",
      "Epoch 15/20\n",
      "1125/1125 [==============================] - 1s 931us/step - loss: 88622.5938 - val_loss: 87336.4844\n",
      "Epoch 16/20\n",
      "1125/1125 [==============================] - 1s 912us/step - loss: 88622.5312 - val_loss: 87336.4844\n",
      "Epoch 17/20\n",
      "1125/1125 [==============================] - 1s 956us/step - loss: 88622.5469 - val_loss: 87336.4844\n",
      "Epoch 18/20\n",
      "1125/1125 [==============================] - 1s 936us/step - loss: 88622.5938 - val_loss: 87336.4844\n",
      "Epoch 19/20\n",
      "1125/1125 [==============================] - 1s 986us/step - loss: 88622.5469 - val_loss: 87336.4844\n",
      "Epoch 20/20\n",
      "1125/1125 [==============================] - 1s 1ms/step - loss: 88622.5547 - val_loss: 87336.4844\n",
      "282/282 [==============================] - 0s 596us/step\n",
      "94/94 [==============================] - 0s 584us/step\n",
      "Model: 4\n",
      "Mean Squared Error: 4255.151\n",
      "--------------------\n",
      "Epoch 1/20\n",
      "1125/1125 [==============================] - 2s 1ms/step - loss: 65782.6328 - val_loss: 45830.1875\n",
      "Epoch 2/20\n",
      "1125/1125 [==============================] - 1s 922us/step - loss: 34422.0586 - val_loss: 23672.1777\n",
      "Epoch 3/20\n",
      "1125/1125 [==============================] - 1s 909us/step - loss: 18355.7305 - val_loss: 13199.2109\n",
      "Epoch 4/20\n",
      "1125/1125 [==============================] - 1s 921us/step - loss: 10452.9697 - val_loss: 7474.0571\n",
      "Epoch 5/20\n",
      "1125/1125 [==============================] - 1s 899us/step - loss: 6406.0308 - val_loss: 4997.7593\n",
      "Epoch 6/20\n",
      "1125/1125 [==============================] - 1s 939us/step - loss: 4685.1440 - val_loss: 4051.9299\n",
      "Epoch 7/20\n",
      "1125/1125 [==============================] - 1s 900us/step - loss: 3968.3716 - val_loss: 3609.6589\n",
      "Epoch 8/20\n",
      "1125/1125 [==============================] - 1s 915us/step - loss: 3613.8838 - val_loss: 3407.7026\n",
      "Epoch 9/20\n",
      "1125/1125 [==============================] - 1s 919us/step - loss: 3368.5674 - val_loss: 3184.5012\n",
      "Epoch 10/20\n",
      "1125/1125 [==============================] - 1s 924us/step - loss: 3201.3145 - val_loss: 3058.9360\n",
      "Epoch 11/20\n",
      "1125/1125 [==============================] - 1s 930us/step - loss: 3058.5947 - val_loss: 2947.8428\n",
      "Epoch 12/20\n",
      "1125/1125 [==============================] - 1s 905us/step - loss: 2958.9607 - val_loss: 2838.8621\n",
      "Epoch 13/20\n",
      "1125/1125 [==============================] - 1s 909us/step - loss: 2868.3318 - val_loss: 2844.7798\n",
      "Epoch 14/20\n",
      "1125/1125 [==============================] - 1s 938us/step - loss: 2823.2273 - val_loss: 2770.3174\n",
      "Epoch 15/20\n",
      "1125/1125 [==============================] - 1s 999us/step - loss: 2767.5830 - val_loss: 2765.5266\n",
      "Epoch 16/20\n",
      "1125/1125 [==============================] - 1s 914us/step - loss: 2724.4106 - val_loss: 2786.7683\n",
      "Epoch 17/20\n",
      "1125/1125 [==============================] - 1s 908us/step - loss: 2698.3511 - val_loss: 2680.2156\n",
      "Epoch 18/20\n",
      "1125/1125 [==============================] - 1s 914us/step - loss: 2654.2588 - val_loss: 2682.2791\n",
      "Epoch 19/20\n",
      "1125/1125 [==============================] - 1s 921us/step - loss: 2629.7961 - val_loss: 2644.6187\n",
      "Epoch 20/20\n",
      "1125/1125 [==============================] - 1s 935us/step - loss: 2601.1350 - val_loss: 2610.8401\n",
      "282/282 [==============================] - 0s 562us/step\n",
      "94/94 [==============================] - 0s 591us/step\n",
      "Model: 5\n",
      "Mean Squared Error: 2925.887333333333\n",
      "--------------------\n",
      "Average Mean Squared Error: 3557.7468\n"
     ]
    }
   ],
   "source": [
    "# Model-2: Add a fully connected layer with 32 neurons with sigmoid activation\n",
    "# and glorot uniform kernel initializer. Add a fully connected layer layer with 8\n",
    "# neurons, sigmoid activation and glorot normal as kernel initializer. Add a fully\n",
    "# connected layer with 1 neuron, relu activation function and he uniform as\n",
    "# kernel initializer. Use Adam optimizer with batch size 8, learning rate 0.01\n",
    "# and epochs set to 20. Extract the features from second last fully connected\n",
    "# layer (having 8 neurons) and model it using a Support Vector regressor.\n",
    "\n",
    "from keras.models import Model\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "def model2(X_train, X_val, y_train, y_val):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, activation='sigmoid', kernel_initializer='glorot_uniform'))\n",
    "    model.add(Dense(8, activation='sigmoid', kernel_initializer='glorot_normal'))\n",
    "    model.add(Dense(1, activation='relu', kernel_initializer='he_uniform'))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.01), loss='mean_squared_error')\n",
    "\n",
    "    model.fit(X_train, y_train, batch_size=8, epochs=20, validation_data=(X_val, y_val))\n",
    "\n",
    "    intermediate_layer_model = Model(inputs=model.input, outputs=model.layers[-2].output)\n",
    "    intermediate_output = intermediate_layer_model.predict(X_train)\n",
    "\n",
    "    svr = SVR()\n",
    "    svr.fit(intermediate_output, y_train)\n",
    "\n",
    "    return model, svr\n",
    "\n",
    "count = 5\n",
    "avg_mse = 0\n",
    "\n",
    "for i in range(count):\n",
    "    # Split data to 60% training 20% validation and 20% testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "    model, svr = model2(X_train, X_val, y_train, y_val)\n",
    "    \n",
    "    intermediate_output = model.layers[-2].output\n",
    "    intermediate_layer_model = Model(inputs=model.input, outputs=intermediate_output)\n",
    "    intermediate_output = intermediate_layer_model.predict(X_test)\n",
    "\n",
    "    y_pred = svr.predict(intermediate_output)\n",
    "\n",
    "    print('Model:', i+1)\n",
    "    y_pred = np.round(y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print('Mean Squared Error:', mse)\n",
    "    print(\"--------------------\")\n",
    "    avg_mse += mse\n",
    "\n",
    "print('Average Mean Squared Error:', avg_mse/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 11945.1299 - val_loss: 3144.1050\n",
      "Epoch 2/20\n",
      "563/563 [==============================] - 1s 948us/step - loss: 3207.5786 - val_loss: 3050.7461\n",
      "Epoch 3/20\n",
      "563/563 [==============================] - 1s 944us/step - loss: 3104.2451 - val_loss: 2954.7461\n",
      "Epoch 4/20\n",
      "563/563 [==============================] - 1s 954us/step - loss: 3062.3867 - val_loss: 3009.6094\n",
      "Epoch 5/20\n",
      "563/563 [==============================] - 1s 957us/step - loss: 3024.0359 - val_loss: 2870.3667\n",
      "Epoch 6/20\n",
      "563/563 [==============================] - 1s 939us/step - loss: 2983.6787 - val_loss: 2916.1250\n",
      "Epoch 7/20\n",
      "563/563 [==============================] - 1s 986us/step - loss: 2919.1902 - val_loss: 2819.6453\n",
      "Epoch 8/20\n",
      "563/563 [==============================] - 1s 993us/step - loss: 2906.6006 - val_loss: 2790.2700\n",
      "Epoch 9/20\n",
      "563/563 [==============================] - 1s 936us/step - loss: 2873.9065 - val_loss: 2809.4346\n",
      "Epoch 10/20\n",
      "563/563 [==============================] - 1s 947us/step - loss: 2847.3323 - val_loss: 2740.3032\n",
      "Epoch 11/20\n",
      "563/563 [==============================] - 1s 945us/step - loss: 2797.2759 - val_loss: 2711.7197\n",
      "Epoch 12/20\n",
      "563/563 [==============================] - 1s 936us/step - loss: 2786.1023 - val_loss: 2716.6248\n",
      "Epoch 13/20\n",
      "563/563 [==============================] - 1s 938us/step - loss: 2747.5251 - val_loss: 2693.9026\n",
      "Epoch 14/20\n",
      "563/563 [==============================] - 1s 949us/step - loss: 2735.9082 - val_loss: 2767.4211\n",
      "Epoch 15/20\n",
      "563/563 [==============================] - 1s 944us/step - loss: 2725.5481 - val_loss: 2674.4001\n",
      "Epoch 16/20\n",
      "563/563 [==============================] - 1s 944us/step - loss: 2701.1360 - val_loss: 2688.4128\n",
      "Epoch 17/20\n",
      "563/563 [==============================] - 1s 976us/step - loss: 2695.2520 - val_loss: 2674.8105\n",
      "Epoch 18/20\n",
      "563/563 [==============================] - 1s 954us/step - loss: 2692.1406 - val_loss: 2701.1467\n",
      "Epoch 19/20\n",
      "563/563 [==============================] - 1s 947us/step - loss: 2658.6807 - val_loss: 2639.5505\n",
      "Epoch 20/20\n",
      "563/563 [==============================] - 1s 951us/step - loss: 2652.3108 - val_loss: 2638.8616\n",
      "Epoch 1/20\n",
      "1125/1125 [==============================] - 2s 993us/step - loss: 88622.5312 - val_loss: 87336.4844\n",
      "Epoch 2/20\n",
      "1125/1125 [==============================] - 1s 904us/step - loss: 88622.5391 - val_loss: 87336.4844\n",
      "Epoch 3/20\n",
      "1125/1125 [==============================] - 1s 947us/step - loss: 88622.5312 - val_loss: 87336.4844\n",
      "Epoch 4/20\n",
      "1125/1125 [==============================] - 1s 905us/step - loss: 88622.5625 - val_loss: 87336.4844\n",
      "Epoch 5/20\n",
      "1125/1125 [==============================] - 1s 912us/step - loss: 88622.5859 - val_loss: 87336.4844\n",
      "Epoch 6/20\n",
      "1125/1125 [==============================] - 1s 922us/step - loss: 88622.6172 - val_loss: 87336.4844\n",
      "Epoch 7/20\n",
      "1125/1125 [==============================] - 1s 994us/step - loss: 88622.6094 - val_loss: 87336.4844\n",
      "Epoch 8/20\n",
      "1125/1125 [==============================] - 1s 1ms/step - loss: 88622.5234 - val_loss: 87336.4844\n",
      "Epoch 9/20\n",
      "1125/1125 [==============================] - 1s 966us/step - loss: 88622.5938 - val_loss: 87336.4844\n",
      "Epoch 10/20\n",
      "1125/1125 [==============================] - 1s 954us/step - loss: 88622.6094 - val_loss: 87336.4844\n",
      "Epoch 11/20\n",
      "1125/1125 [==============================] - 1s 932us/step - loss: 88622.6094 - val_loss: 87336.4844\n",
      "Epoch 12/20\n",
      "1125/1125 [==============================] - 1s 1ms/step - loss: 88622.5000 - val_loss: 87336.4844\n",
      "Epoch 13/20\n",
      "1125/1125 [==============================] - 1s 961us/step - loss: 88622.6250 - val_loss: 87336.4844\n",
      "Epoch 14/20\n",
      "1125/1125 [==============================] - 1s 997us/step - loss: 88622.5781 - val_loss: 87336.4844\n",
      "Epoch 15/20\n",
      "1125/1125 [==============================] - 1s 950us/step - loss: 88622.5391 - val_loss: 87336.4844\n",
      "Epoch 16/20\n",
      "1125/1125 [==============================] - 1s 983us/step - loss: 88622.4766 - val_loss: 87336.4844\n",
      "Epoch 17/20\n",
      "1125/1125 [==============================] - 1s 1000us/step - loss: 88622.5938 - val_loss: 87336.4844\n",
      "Epoch 18/20\n",
      "1125/1125 [==============================] - 1s 1ms/step - loss: 88622.5391 - val_loss: 87336.4844\n",
      "Epoch 19/20\n",
      "1125/1125 [==============================] - 1s 985us/step - loss: 88622.5547 - val_loss: 87336.4844\n",
      "Epoch 20/20\n",
      "1125/1125 [==============================] - 1s 984us/step - loss: 88622.6719 - val_loss: 87336.4844\n",
      "282/282 [==============================] - 0s 741us/step\n",
      "282/282 [==============================] - 0s 566us/step\n",
      "282/282 [==============================] - 0s 563us/step\n",
      "94/94 [==============================] - 0s 587us/step\n",
      "94/94 [==============================] - 0s 600us/step\n",
      "Model: 1\n",
      "Mean Squared Error: 2954.1633333333334\n",
      "--------------------\n",
      "Epoch 1/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 10008.2842 - val_loss: 3086.7427\n",
      "Epoch 2/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 3199.8962 - val_loss: 3036.8157\n",
      "Epoch 3/20\n",
      "563/563 [==============================] - 1s 970us/step - loss: 3123.4253 - val_loss: 3047.5601\n",
      "Epoch 4/20\n",
      "563/563 [==============================] - 1s 977us/step - loss: 3061.5872 - val_loss: 2951.2502\n",
      "Epoch 5/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 3012.5869 - val_loss: 2886.9316\n",
      "Epoch 6/20\n",
      "563/563 [==============================] - 1s 980us/step - loss: 2969.0300 - val_loss: 2820.8374\n",
      "Epoch 7/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2940.1226 - val_loss: 2827.8354\n",
      "Epoch 8/20\n",
      "563/563 [==============================] - 1s 986us/step - loss: 2898.6726 - val_loss: 2811.5676\n",
      "Epoch 9/20\n",
      "563/563 [==============================] - 1s 985us/step - loss: 2856.5151 - val_loss: 2772.6782\n",
      "Epoch 10/20\n",
      "563/563 [==============================] - 1s 962us/step - loss: 2817.8313 - val_loss: 2767.0742\n",
      "Epoch 11/20\n",
      "563/563 [==============================] - 1s 977us/step - loss: 2818.6040 - val_loss: 2770.4902\n",
      "Epoch 12/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2793.7268 - val_loss: 2693.3662\n",
      "Epoch 13/20\n",
      "563/563 [==============================] - 1s 964us/step - loss: 2762.7043 - val_loss: 2681.4985\n",
      "Epoch 14/20\n",
      "563/563 [==============================] - 1s 972us/step - loss: 2769.4031 - val_loss: 2737.4854\n",
      "Epoch 15/20\n",
      "563/563 [==============================] - 1s 973us/step - loss: 2734.2690 - val_loss: 2677.8940\n",
      "Epoch 16/20\n",
      "563/563 [==============================] - 1s 968us/step - loss: 2720.9526 - val_loss: 2679.7388\n",
      "Epoch 17/20\n",
      "563/563 [==============================] - 1s 975us/step - loss: 2706.3804 - val_loss: 2651.6670\n",
      "Epoch 18/20\n",
      "563/563 [==============================] - 1s 995us/step - loss: 2692.2712 - val_loss: 2663.7329\n",
      "Epoch 19/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2692.7522 - val_loss: 2690.6167\n",
      "Epoch 20/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2681.3787 - val_loss: 2732.4475\n",
      "Epoch 1/20\n",
      "1125/1125 [==============================] - 2s 983us/step - loss: 67907.6797 - val_loss: 50208.4688\n",
      "Epoch 2/20\n",
      "1125/1125 [==============================] - 1s 923us/step - loss: 39273.8203 - val_loss: 28356.7012\n",
      "Epoch 3/20\n",
      "1125/1125 [==============================] - 1s 923us/step - loss: 22283.9648 - val_loss: 16109.8799\n",
      "Epoch 4/20\n",
      "1125/1125 [==============================] - 1s 941us/step - loss: 13354.7168 - val_loss: 9615.3115\n",
      "Epoch 5/20\n",
      "1125/1125 [==============================] - 1s 934us/step - loss: 8076.1484 - val_loss: 6125.2231\n",
      "Epoch 6/20\n",
      "1125/1125 [==============================] - 1s 950us/step - loss: 5527.2432 - val_loss: 4522.5806\n",
      "Epoch 7/20\n",
      "1125/1125 [==============================] - 1s 932us/step - loss: 4330.6958 - val_loss: 3756.8506\n",
      "Epoch 8/20\n",
      "1125/1125 [==============================] - 1s 938us/step - loss: 3760.5964 - val_loss: 3498.5200\n",
      "Epoch 9/20\n",
      "1125/1125 [==============================] - 1s 941us/step - loss: 3485.5964 - val_loss: 3288.3403\n",
      "Epoch 10/20\n",
      "1125/1125 [==============================] - 1s 921us/step - loss: 3286.4666 - val_loss: 3183.3677\n",
      "Epoch 11/20\n",
      "1125/1125 [==============================] - 1s 933us/step - loss: 3147.9548 - val_loss: 3096.9766\n",
      "Epoch 12/20\n",
      "1125/1125 [==============================] - 1s 935us/step - loss: 3049.9680 - val_loss: 2979.8027\n",
      "Epoch 13/20\n",
      "1125/1125 [==============================] - 1s 955us/step - loss: 2983.7471 - val_loss: 2975.9221\n",
      "Epoch 14/20\n",
      "1125/1125 [==============================] - 1s 926us/step - loss: 2933.1226 - val_loss: 2877.1814\n",
      "Epoch 15/20\n",
      "1125/1125 [==============================] - 1s 936us/step - loss: 2866.0461 - val_loss: 2826.5002\n",
      "Epoch 16/20\n",
      "1125/1125 [==============================] - 1s 932us/step - loss: 2802.2319 - val_loss: 2901.6204\n",
      "Epoch 17/20\n",
      "1125/1125 [==============================] - 1s 928us/step - loss: 2771.1936 - val_loss: 2822.2219\n",
      "Epoch 18/20\n",
      "1125/1125 [==============================] - 1s 957us/step - loss: 2732.2324 - val_loss: 2794.9041\n",
      "Epoch 19/20\n",
      "1125/1125 [==============================] - 1s 959us/step - loss: 2686.7539 - val_loss: 2760.5459\n",
      "Epoch 20/20\n",
      "1125/1125 [==============================] - 1s 944us/step - loss: 2662.1375 - val_loss: 2680.1074\n",
      "282/282 [==============================] - 0s 558us/step\n",
      "282/282 [==============================] - 0s 564us/step\n",
      "282/282 [==============================] - 0s 575us/step\n",
      "94/94 [==============================] - 0s 601us/step\n",
      "94/94 [==============================] - 0s 568us/step\n",
      "Model: 2\n",
      "Mean Squared Error: 2941.9313333333334\n",
      "--------------------\n",
      "Epoch 1/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 15843.0986 - val_loss: 3322.3120\n",
      "Epoch 2/20\n",
      "563/563 [==============================] - 1s 959us/step - loss: 3298.2097 - val_loss: 3056.3147\n",
      "Epoch 3/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 3130.4861 - val_loss: 3062.8611\n",
      "Epoch 4/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 3061.1362 - val_loss: 2918.4043\n",
      "Epoch 5/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 3004.3521 - val_loss: 2834.7302\n",
      "Epoch 6/20\n",
      "563/563 [==============================] - 1s 971us/step - loss: 2959.3403 - val_loss: 2822.2686\n",
      "Epoch 7/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2920.4324 - val_loss: 2777.1992\n",
      "Epoch 8/20\n",
      "563/563 [==============================] - 1s 969us/step - loss: 2872.3311 - val_loss: 2829.3567\n",
      "Epoch 9/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2853.6587 - val_loss: 2739.7109\n",
      "Epoch 10/20\n",
      "563/563 [==============================] - 1s 979us/step - loss: 2813.7317 - val_loss: 2746.7163\n",
      "Epoch 11/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2788.6794 - val_loss: 2799.6951\n",
      "Epoch 12/20\n",
      "563/563 [==============================] - 1s 993us/step - loss: 2759.4102 - val_loss: 2685.9041\n",
      "Epoch 13/20\n",
      "563/563 [==============================] - 1s 985us/step - loss: 2740.9377 - val_loss: 2697.0869\n",
      "Epoch 14/20\n",
      "563/563 [==============================] - 1s 961us/step - loss: 2727.9089 - val_loss: 2749.1265\n",
      "Epoch 15/20\n",
      "563/563 [==============================] - 1s 972us/step - loss: 2707.5010 - val_loss: 2666.6025\n",
      "Epoch 16/20\n",
      "563/563 [==============================] - 1s 961us/step - loss: 2694.9565 - val_loss: 2670.0474\n",
      "Epoch 17/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2677.3201 - val_loss: 2667.7393\n",
      "Epoch 18/20\n",
      "563/563 [==============================] - 1s 982us/step - loss: 2675.4624 - val_loss: 2681.0649\n",
      "Epoch 19/20\n",
      "563/563 [==============================] - 1s 985us/step - loss: 2665.0234 - val_loss: 2653.2661\n",
      "Epoch 20/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2645.5740 - val_loss: 2671.2068\n",
      "Epoch 1/20\n",
      "1125/1125 [==============================] - 2s 982us/step - loss: 88622.4922 - val_loss: 87336.4844\n",
      "Epoch 2/20\n",
      "1125/1125 [==============================] - 1s 962us/step - loss: 88622.6250 - val_loss: 87336.4844\n",
      "Epoch 3/20\n",
      "1125/1125 [==============================] - 1s 937us/step - loss: 88622.5859 - val_loss: 87336.4844\n",
      "Epoch 4/20\n",
      "1125/1125 [==============================] - 1s 953us/step - loss: 88622.5000 - val_loss: 87336.4844\n",
      "Epoch 5/20\n",
      "1125/1125 [==============================] - 1s 928us/step - loss: 88622.6562 - val_loss: 87336.4844\n",
      "Epoch 6/20\n",
      "1125/1125 [==============================] - 1s 932us/step - loss: 88622.5312 - val_loss: 87336.4844\n",
      "Epoch 7/20\n",
      "1125/1125 [==============================] - 1s 903us/step - loss: 88622.6094 - val_loss: 87336.4844\n",
      "Epoch 8/20\n",
      "1125/1125 [==============================] - 1s 908us/step - loss: 88622.5312 - val_loss: 87336.4844\n",
      "Epoch 9/20\n",
      "1125/1125 [==============================] - 1s 910us/step - loss: 88622.4688 - val_loss: 87336.4844\n",
      "Epoch 10/20\n",
      "1125/1125 [==============================] - 1s 912us/step - loss: 88622.5312 - val_loss: 87336.4844\n",
      "Epoch 11/20\n",
      "1125/1125 [==============================] - 1s 929us/step - loss: 88622.5625 - val_loss: 87336.4844\n",
      "Epoch 12/20\n",
      "1125/1125 [==============================] - 1s 912us/step - loss: 88622.6250 - val_loss: 87336.4844\n",
      "Epoch 13/20\n",
      "1125/1125 [==============================] - 1s 913us/step - loss: 88622.5156 - val_loss: 87336.4844\n",
      "Epoch 14/20\n",
      "1125/1125 [==============================] - 1s 907us/step - loss: 88622.5234 - val_loss: 87336.4844\n",
      "Epoch 15/20\n",
      "1125/1125 [==============================] - 1s 942us/step - loss: 88622.6094 - val_loss: 87336.4844\n",
      "Epoch 16/20\n",
      "1125/1125 [==============================] - 1s 909us/step - loss: 88622.5391 - val_loss: 87336.4844\n",
      "Epoch 17/20\n",
      "1125/1125 [==============================] - 1s 925us/step - loss: 88622.5156 - val_loss: 87336.4844\n",
      "Epoch 18/20\n",
      "1125/1125 [==============================] - 1s 900us/step - loss: 88622.5547 - val_loss: 87336.4844\n",
      "Epoch 19/20\n",
      "1125/1125 [==============================] - 1s 907us/step - loss: 88622.5312 - val_loss: 87336.4844\n",
      "Epoch 20/20\n",
      "1125/1125 [==============================] - 1s 901us/step - loss: 88622.4922 - val_loss: 87336.4844\n",
      "282/282 [==============================] - 0s 568us/step\n",
      "282/282 [==============================] - 0s 577us/step\n",
      "282/282 [==============================] - 0s 602us/step\n",
      "94/94 [==============================] - 0s 547us/step\n",
      "94/94 [==============================] - 0s 606us/step\n",
      "Model: 3\n",
      "Mean Squared Error: 2911.193\n",
      "--------------------\n",
      "Epoch 1/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 11374.5020 - val_loss: 3233.7229\n",
      "Epoch 2/20\n",
      "563/563 [==============================] - 1s 938us/step - loss: 3212.9531 - val_loss: 3052.9551\n",
      "Epoch 3/20\n",
      "563/563 [==============================] - 1s 946us/step - loss: 3117.6724 - val_loss: 3059.5913\n",
      "Epoch 4/20\n",
      "563/563 [==============================] - 1s 941us/step - loss: 3053.8989 - val_loss: 2909.4988\n",
      "Epoch 5/20\n",
      "563/563 [==============================] - 1s 938us/step - loss: 2995.6077 - val_loss: 2920.9871\n",
      "Epoch 6/20\n",
      "563/563 [==============================] - 1s 941us/step - loss: 2989.5183 - val_loss: 2851.5503\n",
      "Epoch 7/20\n",
      "563/563 [==============================] - 1s 946us/step - loss: 2943.0027 - val_loss: 2812.1689\n",
      "Epoch 8/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2915.3879 - val_loss: 2800.5566\n",
      "Epoch 9/20\n",
      "563/563 [==============================] - 1s 944us/step - loss: 2887.6794 - val_loss: 2792.9456\n",
      "Epoch 10/20\n",
      "563/563 [==============================] - 1s 943us/step - loss: 2842.5486 - val_loss: 2780.5901\n",
      "Epoch 11/20\n",
      "563/563 [==============================] - 1s 947us/step - loss: 2818.5352 - val_loss: 2755.5859\n",
      "Epoch 12/20\n",
      "563/563 [==============================] - 1s 941us/step - loss: 2792.4785 - val_loss: 2706.9338\n",
      "Epoch 13/20\n",
      "563/563 [==============================] - 1s 935us/step - loss: 2770.8945 - val_loss: 2689.1570\n",
      "Epoch 14/20\n",
      "563/563 [==============================] - 1s 966us/step - loss: 2751.1440 - val_loss: 2703.7961\n",
      "Epoch 15/20\n",
      "563/563 [==============================] - 1s 936us/step - loss: 2737.9888 - val_loss: 2707.7153\n",
      "Epoch 16/20\n",
      "563/563 [==============================] - 1s 949us/step - loss: 2719.6448 - val_loss: 2646.6394\n",
      "Epoch 17/20\n",
      "563/563 [==============================] - 1s 941us/step - loss: 2694.7947 - val_loss: 2629.0342\n",
      "Epoch 18/20\n",
      "563/563 [==============================] - 1s 974us/step - loss: 2680.5015 - val_loss: 2662.9802\n",
      "Epoch 19/20\n",
      "563/563 [==============================] - 1s 969us/step - loss: 2673.4509 - val_loss: 2650.8433\n",
      "Epoch 20/20\n",
      "563/563 [==============================] - 1s 938us/step - loss: 2638.3816 - val_loss: 2653.0955\n",
      "Epoch 1/20\n",
      "1125/1125 [==============================] - 2s 989us/step - loss: 65439.1523 - val_loss: 46109.1953\n",
      "Epoch 2/20\n",
      "1125/1125 [==============================] - 1s 888us/step - loss: 34734.4922 - val_loss: 23958.7949\n",
      "Epoch 3/20\n",
      "1125/1125 [==============================] - 1s 930us/step - loss: 18531.0977 - val_loss: 13278.2842\n",
      "Epoch 4/20\n",
      "1125/1125 [==============================] - 1s 948us/step - loss: 10634.4209 - val_loss: 7512.2915\n",
      "Epoch 5/20\n",
      "1125/1125 [==============================] - 1s 911us/step - loss: 6453.9033 - val_loss: 5047.6694\n",
      "Epoch 6/20\n",
      "1125/1125 [==============================] - 1s 915us/step - loss: 4686.8350 - val_loss: 4007.0200\n",
      "Epoch 7/20\n",
      "1125/1125 [==============================] - 1s 922us/step - loss: 3966.6555 - val_loss: 3594.4431\n",
      "Epoch 8/20\n",
      "1125/1125 [==============================] - 1s 924us/step - loss: 3598.4419 - val_loss: 3369.2991\n",
      "Epoch 9/20\n",
      "1125/1125 [==============================] - 1s 950us/step - loss: 3369.0508 - val_loss: 3182.1599\n",
      "Epoch 10/20\n",
      "1125/1125 [==============================] - 1s 940us/step - loss: 3195.1226 - val_loss: 3012.5601\n",
      "Epoch 11/20\n",
      "1125/1125 [==============================] - 1s 931us/step - loss: 3059.9275 - val_loss: 2962.7993\n",
      "Epoch 12/20\n",
      "1125/1125 [==============================] - 1s 982us/step - loss: 2957.8379 - val_loss: 2888.3547\n",
      "Epoch 13/20\n",
      "1125/1125 [==============================] - 1s 965us/step - loss: 2895.9822 - val_loss: 2851.3584\n",
      "Epoch 14/20\n",
      "1125/1125 [==============================] - 1s 995us/step - loss: 2828.6726 - val_loss: 2879.9460\n",
      "Epoch 15/20\n",
      "1125/1125 [==============================] - 1s 937us/step - loss: 2779.7605 - val_loss: 2831.8049\n",
      "Epoch 16/20\n",
      "1125/1125 [==============================] - 1s 987us/step - loss: 2750.8254 - val_loss: 2843.3196\n",
      "Epoch 17/20\n",
      "1125/1125 [==============================] - 1s 977us/step - loss: 2719.9065 - val_loss: 2764.3765\n",
      "Epoch 18/20\n",
      "1125/1125 [==============================] - 1s 974us/step - loss: 2686.2427 - val_loss: 2740.7009\n",
      "Epoch 19/20\n",
      "1125/1125 [==============================] - 1s 939us/step - loss: 2658.5042 - val_loss: 2986.2676\n",
      "Epoch 20/20\n",
      "1125/1125 [==============================] - 1s 924us/step - loss: 2627.6296 - val_loss: 2740.8047\n",
      "282/282 [==============================] - 0s 573us/step\n",
      "282/282 [==============================] - 0s 534us/step\n",
      "282/282 [==============================] - 1s 579us/step\n",
      "94/94 [==============================] - 0s 606us/step\n",
      "94/94 [==============================] - 0s 579us/step\n",
      "Model: 4\n",
      "Mean Squared Error: 2947.3006666666665\n",
      "--------------------\n",
      "Epoch 1/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 10915.9609 - val_loss: 3164.4871\n",
      "Epoch 2/20\n",
      "563/563 [==============================] - 1s 952us/step - loss: 3185.9873 - val_loss: 3028.2126\n",
      "Epoch 3/20\n",
      "563/563 [==============================] - 1s 945us/step - loss: 3102.9368 - val_loss: 2979.6736\n",
      "Epoch 4/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 3045.3047 - val_loss: 2911.9377\n",
      "Epoch 5/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2985.3445 - val_loss: 2896.5117\n",
      "Epoch 6/20\n",
      "563/563 [==============================] - 1s 991us/step - loss: 2939.1321 - val_loss: 2802.6816\n",
      "Epoch 7/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2895.9390 - val_loss: 2769.5337\n",
      "Epoch 8/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2867.9121 - val_loss: 2810.2520\n",
      "Epoch 9/20\n",
      "563/563 [==============================] - 1s 995us/step - loss: 2854.7891 - val_loss: 2918.4690\n",
      "Epoch 10/20\n",
      "563/563 [==============================] - 1s 944us/step - loss: 2811.3318 - val_loss: 2835.1299\n",
      "Epoch 11/20\n",
      "563/563 [==============================] - 1s 940us/step - loss: 2789.8201 - val_loss: 2711.3501\n",
      "Epoch 12/20\n",
      "563/563 [==============================] - 1s 933us/step - loss: 2771.0442 - val_loss: 2682.3149\n",
      "Epoch 13/20\n",
      "563/563 [==============================] - 1s 984us/step - loss: 2758.7185 - val_loss: 2788.6262\n",
      "Epoch 14/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2742.7712 - val_loss: 2645.6934\n",
      "Epoch 15/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2708.8718 - val_loss: 2634.6711\n",
      "Epoch 16/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2692.5630 - val_loss: 2686.2200\n",
      "Epoch 17/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2681.3235 - val_loss: 2651.9294\n",
      "Epoch 18/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2666.9790 - val_loss: 2709.1372\n",
      "Epoch 19/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2656.7449 - val_loss: 2613.7534\n",
      "Epoch 20/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2641.9241 - val_loss: 2622.5774\n",
      "Epoch 1/20\n",
      "1125/1125 [==============================] - 2s 1ms/step - loss: 67999.8750 - val_loss: 49615.8359\n",
      "Epoch 2/20\n",
      "1125/1125 [==============================] - 1s 948us/step - loss: 36012.0352 - val_loss: 24438.2070\n",
      "Epoch 3/20\n",
      "1125/1125 [==============================] - 1s 909us/step - loss: 18821.8555 - val_loss: 13426.3096\n",
      "Epoch 4/20\n",
      "1125/1125 [==============================] - 1s 914us/step - loss: 10722.9043 - val_loss: 7626.0527\n",
      "Epoch 5/20\n",
      "1125/1125 [==============================] - 1s 956us/step - loss: 6487.3135 - val_loss: 5053.8169\n",
      "Epoch 6/20\n",
      "1125/1125 [==============================] - 1s 964us/step - loss: 4734.0684 - val_loss: 4090.6057\n",
      "Epoch 7/20\n",
      "1125/1125 [==============================] - 1s 955us/step - loss: 4015.6636 - val_loss: 3613.6758\n",
      "Epoch 8/20\n",
      "1125/1125 [==============================] - 1s 996us/step - loss: 3612.7224 - val_loss: 3331.2336\n",
      "Epoch 9/20\n",
      "1125/1125 [==============================] - 1s 919us/step - loss: 3328.5527 - val_loss: 3157.3040\n",
      "Epoch 10/20\n",
      "1125/1125 [==============================] - 1s 1ms/step - loss: 3128.5178 - val_loss: 2980.0500\n",
      "Epoch 11/20\n",
      "1125/1125 [==============================] - 1s 1ms/step - loss: 3006.2302 - val_loss: 2922.2612\n",
      "Epoch 12/20\n",
      "1125/1125 [==============================] - 1s 1ms/step - loss: 2917.0210 - val_loss: 2861.4727\n",
      "Epoch 13/20\n",
      "1125/1125 [==============================] - 1s 1ms/step - loss: 2865.1323 - val_loss: 2915.9761\n",
      "Epoch 14/20\n",
      "1125/1125 [==============================] - 1s 927us/step - loss: 2822.1267 - val_loss: 2785.9866\n",
      "Epoch 15/20\n",
      "1125/1125 [==============================] - 1s 950us/step - loss: 2778.6267 - val_loss: 2766.4812\n",
      "Epoch 16/20\n",
      "1125/1125 [==============================] - 1s 945us/step - loss: 2731.3921 - val_loss: 2797.2014\n",
      "Epoch 17/20\n",
      "1125/1125 [==============================] - 1s 957us/step - loss: 2709.2686 - val_loss: 2775.4104\n",
      "Epoch 18/20\n",
      "1125/1125 [==============================] - 1s 920us/step - loss: 2692.0420 - val_loss: 2726.1853\n",
      "Epoch 19/20\n",
      "1125/1125 [==============================] - 1s 950us/step - loss: 2665.0259 - val_loss: 2686.8391\n",
      "Epoch 20/20\n",
      "1125/1125 [==============================] - 1s 925us/step - loss: 2632.2463 - val_loss: 2721.8665\n",
      "282/282 [==============================] - 0s 571us/step\n",
      "282/282 [==============================] - 0s 565us/step\n",
      "282/282 [==============================] - 0s 597us/step\n",
      "94/94 [==============================] - 0s 626us/step\n",
      "94/94 [==============================] - 0s 649us/step\n",
      "Model: 5\n",
      "Mean Squared Error: 2959.4843333333333\n",
      "--------------------\n",
      "Average Mean Squared Error: 2942.814533333333\n"
     ]
    }
   ],
   "source": [
    "# Model-3: Extract the deep features from Model-I (from 2nd layer) and Model-\n",
    "# 2 (from 2nd layer) stack the features horizontally and model it using a Support\n",
    "# Vector Regressor.\n",
    "\n",
    "def model3(X_train, X_val, y_train, y_val):\n",
    "    model_1 = model1(X_train, X_val, y_train, y_val)\n",
    "    model_2, _ = model2(X_train, X_val, y_train, y_val)\n",
    "\n",
    "    intermediate_output1 = model_1.layers[-2].output\n",
    "    intermediate_output2 = model_2.layers[-2].output\n",
    "\n",
    "    intermediate_layer_model_1 = Model(inputs=model_1.input, outputs=intermediate_output1)\n",
    "\n",
    "    intermediate_output1 = intermediate_layer_model_1.predict(X_train)\n",
    "\n",
    "    intermediate_layer_model_2 = Model(inputs=model_2.input, outputs=intermediate_output2)\n",
    "\n",
    "    intermediate_output2 = intermediate_layer_model_2.predict(X_train)\n",
    "\n",
    "    intermediate_output = np.hstack((intermediate_output1, intermediate_output2))\n",
    "\n",
    "    svr = SVR()\n",
    "    svr.fit(intermediate_output, y_train)\n",
    "\n",
    "    return model_1, model_2, svr\n",
    "\n",
    "count = 5\n",
    "avg_mse = 0\n",
    "\n",
    "for i in range(count):\n",
    "    # Split data to 60% training 20% validation and 20% testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "    model_1, model_2, svr = model3(X_train, X_val, y_train, y_val)\n",
    "\n",
    "    intermediate_output1 = model_1.layers[-2].output\n",
    "    intermediate_output2 = model_2.layers[-2].output\n",
    "\n",
    "    intermediate_layer_model_1 = Model(inputs=model_1.input, outputs=intermediate_output1)\n",
    "\n",
    "    intermediate_output1 = intermediate_layer_model_1.predict(X_test)\n",
    "\n",
    "    intermediate_layer_model_2 = Model(inputs=model_2.input, outputs=intermediate_output2)\n",
    "\n",
    "    intermediate_output2 = intermediate_layer_model_2.predict(X_test)\n",
    "\n",
    "    intermediate_output = np.hstack((intermediate_output1, intermediate_output2))\n",
    "\n",
    "    y_pred = svr.predict(intermediate_output)\n",
    "\n",
    "    print('Model:', i+1)\n",
    "    y_pred = np.round(y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print('Mean Squared Error:', mse)\n",
    "    print(\"--------------------\")\n",
    "    avg_mse += mse\n",
    "\n",
    "print('Average Mean Squared Error:', avg_mse/count)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 12018.9316 - val_loss: 3243.3008\n",
      "Epoch 2/20\n",
      "563/563 [==============================] - 1s 952us/step - loss: 3221.0396 - val_loss: 3031.9114\n",
      "Epoch 3/20\n",
      "563/563 [==============================] - 1s 952us/step - loss: 3121.9602 - val_loss: 2995.2710\n",
      "Epoch 4/20\n",
      "563/563 [==============================] - 1s 950us/step - loss: 3065.3274 - val_loss: 2928.5117\n",
      "Epoch 5/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 3002.2068 - val_loss: 2973.2566\n",
      "Epoch 6/20\n",
      "563/563 [==============================] - 1s 970us/step - loss: 2976.8367 - val_loss: 2833.1746\n",
      "Epoch 7/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2941.4402 - val_loss: 2808.6130\n",
      "Epoch 8/20\n",
      "563/563 [==============================] - 1s 961us/step - loss: 2891.0303 - val_loss: 2784.0286\n",
      "Epoch 9/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2846.9150 - val_loss: 2838.1917\n",
      "Epoch 10/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2833.8262 - val_loss: 2747.2976\n",
      "Epoch 11/20\n",
      "563/563 [==============================] - 1s 963us/step - loss: 2801.2634 - val_loss: 2732.3027\n",
      "Epoch 12/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2783.2715 - val_loss: 2692.3333\n",
      "Epoch 13/20\n",
      "563/563 [==============================] - 1s 977us/step - loss: 2745.7415 - val_loss: 2709.0298\n",
      "Epoch 14/20\n",
      "563/563 [==============================] - 1s 967us/step - loss: 2738.9697 - val_loss: 2666.6453\n",
      "Epoch 15/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2717.9265 - val_loss: 2682.7349\n",
      "Epoch 16/20\n",
      "563/563 [==============================] - 1s 959us/step - loss: 2706.8298 - val_loss: 2715.1587\n",
      "Epoch 17/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2690.9951 - val_loss: 2657.8647\n",
      "Epoch 18/20\n",
      "563/563 [==============================] - 1s 962us/step - loss: 2686.6980 - val_loss: 2645.9009\n",
      "Epoch 19/20\n",
      "563/563 [==============================] - 1s 964us/step - loss: 2672.1438 - val_loss: 2649.5842\n",
      "Epoch 20/20\n",
      "563/563 [==============================] - 1s 952us/step - loss: 2658.8188 - val_loss: 2859.0193\n",
      "Epoch 1/20\n",
      "1125/1125 [==============================] - 2s 974us/step - loss: 88622.5312 - val_loss: 87336.4844\n",
      "Epoch 2/20\n",
      "1125/1125 [==============================] - 1s 916us/step - loss: 88622.5547 - val_loss: 87336.4844\n",
      "Epoch 3/20\n",
      "1125/1125 [==============================] - 1s 908us/step - loss: 88622.5625 - val_loss: 87336.4844\n",
      "Epoch 4/20\n",
      "1125/1125 [==============================] - 1s 908us/step - loss: 88622.5781 - val_loss: 87336.4844\n",
      "Epoch 5/20\n",
      "1125/1125 [==============================] - 1s 932us/step - loss: 88622.6172 - val_loss: 87336.4844\n",
      "Epoch 6/20\n",
      "1125/1125 [==============================] - 1s 942us/step - loss: 88622.5703 - val_loss: 87336.4844\n",
      "Epoch 7/20\n",
      "1125/1125 [==============================] - 1s 914us/step - loss: 88622.5625 - val_loss: 87336.4844\n",
      "Epoch 8/20\n",
      "1125/1125 [==============================] - 1s 916us/step - loss: 88622.6016 - val_loss: 87336.4844\n",
      "Epoch 9/20\n",
      "1125/1125 [==============================] - 1s 911us/step - loss: 88622.5938 - val_loss: 87336.4844\n",
      "Epoch 10/20\n",
      "1125/1125 [==============================] - 1s 922us/step - loss: 88622.5391 - val_loss: 87336.4844\n",
      "Epoch 11/20\n",
      "1125/1125 [==============================] - 1s 921us/step - loss: 88622.5234 - val_loss: 87336.4844\n",
      "Epoch 12/20\n",
      "1125/1125 [==============================] - 1s 920us/step - loss: 88622.4531 - val_loss: 87336.4844\n",
      "Epoch 13/20\n",
      "1125/1125 [==============================] - 1s 939us/step - loss: 88622.6016 - val_loss: 87336.4844\n",
      "Epoch 14/20\n",
      "1125/1125 [==============================] - 1s 906us/step - loss: 88622.5391 - val_loss: 87336.4844\n",
      "Epoch 15/20\n",
      "1125/1125 [==============================] - 1s 919us/step - loss: 88622.5000 - val_loss: 87336.4844\n",
      "Epoch 16/20\n",
      "1125/1125 [==============================] - 1s 906us/step - loss: 88622.5000 - val_loss: 87336.4844\n",
      "Epoch 17/20\n",
      "1125/1125 [==============================] - 1s 908us/step - loss: 88622.5625 - val_loss: 87336.4844\n",
      "Epoch 18/20\n",
      "1125/1125 [==============================] - 1s 913us/step - loss: 88622.5156 - val_loss: 87336.4844\n",
      "Epoch 19/20\n",
      "1125/1125 [==============================] - 1s 915us/step - loss: 88622.6562 - val_loss: 87336.4844\n",
      "Epoch 20/20\n",
      "1125/1125 [==============================] - 1s 916us/step - loss: 88622.5469 - val_loss: 87336.4844\n",
      "282/282 [==============================] - 0s 563us/step\n",
      "282/282 [==============================] - 0s 587us/step\n",
      "282/282 [==============================] - 0s 609us/step\n",
      "94/94 [==============================] - 0s 573us/step\n",
      "94/94 [==============================] - 0s 600us/step\n",
      "Model: 1\n",
      "Mean Squared Error: 2751.744\n",
      "--------------------\n",
      "Epoch 1/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 10767.2871 - val_loss: 3153.9331\n",
      "Epoch 2/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 3203.0681 - val_loss: 3039.6631\n",
      "Epoch 3/20\n",
      "563/563 [==============================] - 1s 965us/step - loss: 3112.7908 - val_loss: 3025.1003\n",
      "Epoch 4/20\n",
      "563/563 [==============================] - 1s 962us/step - loss: 3061.9187 - val_loss: 2891.5806\n",
      "Epoch 5/20\n",
      "563/563 [==============================] - 1s 946us/step - loss: 3002.6055 - val_loss: 2852.5474\n",
      "Epoch 6/20\n",
      "563/563 [==============================] - 1s 970us/step - loss: 2965.3767 - val_loss: 2826.4072\n",
      "Epoch 7/20\n",
      "563/563 [==============================] - 1s 962us/step - loss: 2921.4915 - val_loss: 2830.2637\n",
      "Epoch 8/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2887.0310 - val_loss: 2815.2571\n",
      "Epoch 9/20\n",
      "563/563 [==============================] - 1s 957us/step - loss: 2846.7131 - val_loss: 2747.7722\n",
      "Epoch 10/20\n",
      "563/563 [==============================] - 1s 968us/step - loss: 2841.8752 - val_loss: 2749.9941\n",
      "Epoch 11/20\n",
      "563/563 [==============================] - 1s 950us/step - loss: 2803.7959 - val_loss: 2705.0662\n",
      "Epoch 12/20\n",
      "563/563 [==============================] - 1s 955us/step - loss: 2786.7690 - val_loss: 2678.4570\n",
      "Epoch 13/20\n",
      "563/563 [==============================] - 1s 962us/step - loss: 2758.8704 - val_loss: 2675.4189\n",
      "Epoch 14/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2745.6851 - val_loss: 2758.2666\n",
      "Epoch 15/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2716.4290 - val_loss: 2674.7649\n",
      "Epoch 16/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2711.8582 - val_loss: 2672.3501\n",
      "Epoch 17/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2703.1418 - val_loss: 2745.0906\n",
      "Epoch 18/20\n",
      "563/563 [==============================] - 1s 967us/step - loss: 2690.7529 - val_loss: 2599.9062\n",
      "Epoch 19/20\n",
      "563/563 [==============================] - 1s 954us/step - loss: 2659.7146 - val_loss: 2661.2976\n",
      "Epoch 20/20\n",
      "563/563 [==============================] - 1s 955us/step - loss: 2651.9465 - val_loss: 2613.2417\n",
      "Epoch 1/20\n",
      "1125/1125 [==============================] - 2s 984us/step - loss: 67900.1016 - val_loss: 49688.4844\n",
      "Epoch 2/20\n",
      "1125/1125 [==============================] - 1s 930us/step - loss: 38784.0742 - val_loss: 27955.9316\n",
      "Epoch 3/20\n",
      "1125/1125 [==============================] - 1s 926us/step - loss: 22007.6113 - val_loss: 15935.0078\n",
      "Epoch 4/20\n",
      "1125/1125 [==============================] - 1s 927us/step - loss: 13163.5498 - val_loss: 9551.4482\n",
      "Epoch 5/20\n",
      "1125/1125 [==============================] - 1s 936us/step - loss: 7959.7734 - val_loss: 6095.4238\n",
      "Epoch 6/20\n",
      "1125/1125 [==============================] - 1s 920us/step - loss: 5461.9897 - val_loss: 4484.7124\n",
      "Epoch 7/20\n",
      "1125/1125 [==============================] - 1s 963us/step - loss: 4357.8691 - val_loss: 3864.6760\n",
      "Epoch 8/20\n",
      "1125/1125 [==============================] - 1s 935us/step - loss: 3848.3577 - val_loss: 3517.2686\n",
      "Epoch 9/20\n",
      "1125/1125 [==============================] - 1s 921us/step - loss: 3515.4355 - val_loss: 3270.2141\n",
      "Epoch 10/20\n",
      "1125/1125 [==============================] - 1s 948us/step - loss: 3284.1584 - val_loss: 3150.5591\n",
      "Epoch 11/20\n",
      "1125/1125 [==============================] - 1s 922us/step - loss: 3130.7966 - val_loss: 3176.7234\n",
      "Epoch 12/20\n",
      "1125/1125 [==============================] - 1s 967us/step - loss: 3034.2661 - val_loss: 3000.8875\n",
      "Epoch 13/20\n",
      "1125/1125 [==============================] - 1s 970us/step - loss: 2943.5398 - val_loss: 2996.8259\n",
      "Epoch 14/20\n",
      "1125/1125 [==============================] - 1s 977us/step - loss: 2881.2192 - val_loss: 2951.4600\n",
      "Epoch 15/20\n",
      "1125/1125 [==============================] - 1s 959us/step - loss: 2820.3438 - val_loss: 2788.2395\n",
      "Epoch 16/20\n",
      "1125/1125 [==============================] - 1s 983us/step - loss: 2768.0042 - val_loss: 2825.8760\n",
      "Epoch 17/20\n",
      "1125/1125 [==============================] - 1s 965us/step - loss: 2723.1584 - val_loss: 2790.7009\n",
      "Epoch 18/20\n",
      "1125/1125 [==============================] - 1s 946us/step - loss: 2687.7739 - val_loss: 2859.9373\n",
      "Epoch 19/20\n",
      "1125/1125 [==============================] - 1s 927us/step - loss: 2671.8323 - val_loss: 2799.7625\n",
      "Epoch 20/20\n",
      "1125/1125 [==============================] - 1s 951us/step - loss: 2639.9915 - val_loss: 2765.1165\n",
      "282/282 [==============================] - 0s 568us/step\n",
      "282/282 [==============================] - 0s 552us/step\n",
      "282/282 [==============================] - 0s 558us/step\n",
      "94/94 [==============================] - 0s 603us/step\n",
      "94/94 [==============================] - 0s 583us/step\n",
      "Model: 2\n",
      "Mean Squared Error: 2708.8306666666667\n",
      "--------------------\n",
      "Epoch 1/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 11276.0439 - val_loss: 3194.4080\n",
      "Epoch 2/20\n",
      "563/563 [==============================] - 1s 951us/step - loss: 3213.0591 - val_loss: 3018.0964\n",
      "Epoch 3/20\n",
      "563/563 [==============================] - 1s 962us/step - loss: 3104.2017 - val_loss: 2983.7410\n",
      "Epoch 4/20\n",
      "563/563 [==============================] - 1s 961us/step - loss: 3054.6670 - val_loss: 3087.4863\n",
      "Epoch 5/20\n",
      "563/563 [==============================] - 1s 951us/step - loss: 2989.3933 - val_loss: 2887.9866\n",
      "Epoch 6/20\n",
      "563/563 [==============================] - 1s 958us/step - loss: 2962.8423 - val_loss: 2833.9929\n",
      "Epoch 7/20\n",
      "563/563 [==============================] - 1s 947us/step - loss: 2928.8777 - val_loss: 2886.5530\n",
      "Epoch 8/20\n",
      "563/563 [==============================] - 1s 966us/step - loss: 2880.7166 - val_loss: 2806.2671\n",
      "Epoch 9/20\n",
      "563/563 [==============================] - 1s 940us/step - loss: 2853.1555 - val_loss: 2784.0635\n",
      "Epoch 10/20\n",
      "563/563 [==============================] - 1s 982us/step - loss: 2818.6426 - val_loss: 2790.7532\n",
      "Epoch 11/20\n",
      "563/563 [==============================] - 1s 949us/step - loss: 2800.3623 - val_loss: 2754.3323\n",
      "Epoch 12/20\n",
      "563/563 [==============================] - 1s 951us/step - loss: 2767.4836 - val_loss: 2812.0967\n",
      "Epoch 13/20\n",
      "563/563 [==============================] - 1s 965us/step - loss: 2739.7710 - val_loss: 2677.5107\n",
      "Epoch 14/20\n",
      "563/563 [==============================] - 1s 945us/step - loss: 2727.3713 - val_loss: 2780.1484\n",
      "Epoch 15/20\n",
      "563/563 [==============================] - 1s 955us/step - loss: 2710.5332 - val_loss: 2711.6396\n",
      "Epoch 16/20\n",
      "563/563 [==============================] - 1s 955us/step - loss: 2689.9541 - val_loss: 2646.1152\n",
      "Epoch 17/20\n",
      "563/563 [==============================] - 1s 966us/step - loss: 2677.2170 - val_loss: 2636.1648\n",
      "Epoch 18/20\n",
      "563/563 [==============================] - 1s 963us/step - loss: 2666.8840 - val_loss: 2805.2483\n",
      "Epoch 19/20\n",
      "563/563 [==============================] - 1s 956us/step - loss: 2663.8379 - val_loss: 2765.0342\n",
      "Epoch 20/20\n",
      "563/563 [==============================] - 1s 1ms/step - loss: 2650.3684 - val_loss: 2640.6350\n",
      "Epoch 1/20\n",
      "1125/1125 [==============================] - 2s 983us/step - loss: 70627.4453 - val_loss: 54774.1289\n",
      "Epoch 2/20\n",
      "1125/1125 [==============================] - 1s 890us/step - loss: 44520.6211 - val_loss: 33750.4648\n",
      "Epoch 3/20\n",
      "1125/1125 [==============================] - 1s 897us/step - loss: 27330.6777 - val_loss: 20420.0059\n",
      "Epoch 4/20\n",
      "1125/1125 [==============================] - 1s 901us/step - loss: 16958.4648 - val_loss: 13038.4492\n",
      "Epoch 5/20\n",
      "1125/1125 [==============================] - 1s 906us/step - loss: 10950.4932 - val_loss: 8117.9341\n",
      "Epoch 6/20\n",
      "1125/1125 [==============================] - 1s 925us/step - loss: 7070.3574 - val_loss: 5639.3013\n",
      "Epoch 7/20\n",
      "1125/1125 [==============================] - 1s 918us/step - loss: 5196.1655 - val_loss: 4349.7949\n",
      "Epoch 8/20\n",
      "1125/1125 [==============================] - 1s 915us/step - loss: 4232.3682 - val_loss: 3728.5803\n",
      "Epoch 9/20\n",
      "1125/1125 [==============================] - 1s 906us/step - loss: 3726.6052 - val_loss: 3450.0049\n",
      "Epoch 10/20\n",
      "1125/1125 [==============================] - 1s 910us/step - loss: 3443.7305 - val_loss: 3251.2944\n",
      "Epoch 11/20\n",
      "1125/1125 [==============================] - 1s 919us/step - loss: 3287.1819 - val_loss: 3198.0391\n",
      "Epoch 12/20\n",
      "1125/1125 [==============================] - 1s 896us/step - loss: 3161.9575 - val_loss: 3018.9136\n",
      "Epoch 13/20\n",
      "1125/1125 [==============================] - 1s 900us/step - loss: 3035.5911 - val_loss: 2963.7300\n",
      "Epoch 14/20\n",
      "1125/1125 [==============================] - 1s 895us/step - loss: 2964.5286 - val_loss: 2920.4534\n",
      "Epoch 15/20\n",
      "1125/1125 [==============================] - 1s 905us/step - loss: 2907.8208 - val_loss: 2963.5071\n",
      "Epoch 16/20\n",
      "1125/1125 [==============================] - 1s 990us/step - loss: 2848.6909 - val_loss: 2921.3130\n",
      "Epoch 17/20\n",
      "1125/1125 [==============================] - 1s 1ms/step - loss: 2811.9121 - val_loss: 2866.0356\n",
      "Epoch 18/20\n",
      "1125/1125 [==============================] - 1s 977us/step - loss: 2774.8027 - val_loss: 2777.5452\n",
      "Epoch 19/20\n",
      "1125/1125 [==============================] - 1s 910us/step - loss: 2741.7505 - val_loss: 2813.3269\n",
      "Epoch 20/20\n",
      "1125/1125 [==============================] - 1s 899us/step - loss: 2725.2898 - val_loss: 2736.0710\n",
      "282/282 [==============================] - 0s 573us/step\n",
      "282/282 [==============================] - 0s 570us/step\n",
      "282/282 [==============================] - 0s 586us/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "Model: 3\n",
      "Mean Squared Error: 2712.2943333333333\n",
      "--------------------\n",
      "Epoch 1/20\n",
      "563/563 [==============================] - 3s 3ms/step - loss: 10751.4883 - val_loss: 3154.7388\n",
      "Epoch 2/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 3199.5081 - val_loss: 3075.0730\n",
      "Epoch 3/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 3126.3303 - val_loss: 3174.5784\n",
      "Epoch 4/20\n",
      "563/563 [==============================] - 1s 3ms/step - loss: 3057.6025 - val_loss: 2944.9746\n",
      "Epoch 5/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2999.4312 - val_loss: 2925.6060\n",
      "Epoch 6/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2970.3677 - val_loss: 2834.4580\n",
      "Epoch 7/20\n",
      "563/563 [==============================] - 1s 3ms/step - loss: 2931.5593 - val_loss: 2988.7781\n",
      "Epoch 8/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2899.4272 - val_loss: 2800.5547\n",
      "Epoch 9/20\n",
      "563/563 [==============================] - 1s 3ms/step - loss: 2864.3623 - val_loss: 2825.7690\n",
      "Epoch 10/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2843.2546 - val_loss: 2839.7546\n",
      "Epoch 11/20\n",
      "563/563 [==============================] - 1s 3ms/step - loss: 2809.5259 - val_loss: 2749.2507\n",
      "Epoch 12/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 2764.2515 - val_loss: 2714.3044\n",
      "Epoch 13/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2776.8154 - val_loss: 2764.1934\n",
      "Epoch 14/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2733.7859 - val_loss: 2703.1675\n",
      "Epoch 15/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2711.7361 - val_loss: 2666.7009\n",
      "Epoch 16/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2703.4900 - val_loss: 2799.2913\n",
      "Epoch 17/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2684.4292 - val_loss: 2662.8787\n",
      "Epoch 18/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2671.5422 - val_loss: 2781.9138\n",
      "Epoch 19/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2654.7490 - val_loss: 2711.8518\n",
      "Epoch 20/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2648.8203 - val_loss: 2653.9724\n",
      "Epoch 1/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 65333.2422 - val_loss: 46315.3281\n",
      "Epoch 2/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 35005.0625 - val_loss: 24182.8926\n",
      "Epoch 3/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 18689.5566 - val_loss: 13376.8877\n",
      "Epoch 4/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 10779.8447 - val_loss: 7606.8179\n",
      "Epoch 5/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 6544.9282 - val_loss: 5092.2881\n",
      "Epoch 6/20\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 4727.1621 - val_loss: 4032.4106\n",
      "Epoch 7/20\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 3943.4658 - val_loss: 3537.9446\n",
      "Epoch 8/20\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 3559.9287 - val_loss: 3312.3313\n",
      "Epoch 9/20\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 3332.1848 - val_loss: 3136.4500\n",
      "Epoch 10/20\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 3142.5432 - val_loss: 3026.4426\n",
      "Epoch 11/20\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 3022.1428 - val_loss: 2995.3538\n",
      "Epoch 12/20\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 2935.3101 - val_loss: 2923.5491\n",
      "Epoch 13/20\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 2875.7134 - val_loss: 2813.4482\n",
      "Epoch 14/20\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 2823.2117 - val_loss: 2821.4646\n",
      "Epoch 15/20\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 2771.0718 - val_loss: 2794.4688\n",
      "Epoch 16/20\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 2734.6453 - val_loss: 2791.9104\n",
      "Epoch 17/20\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 2710.3752 - val_loss: 2784.4641\n",
      "Epoch 18/20\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 2680.8750 - val_loss: 2788.6636\n",
      "Epoch 19/20\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 2656.0449 - val_loss: 2839.7964\n",
      "Epoch 20/20\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 2623.3489 - val_loss: 2734.8628\n",
      "282/282 [==============================] - 0s 1ms/step\n",
      "282/282 [==============================] - 0s 1ms/step\n",
      "282/282 [==============================] - 1s 2ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "Model: 4\n",
      "Mean Squared Error: 2658.7156666666665\n",
      "--------------------\n",
      "Epoch 1/20\n",
      "563/563 [==============================] - 3s 3ms/step - loss: 88622.5938 - val_loss: 87336.4453\n",
      "Epoch 2/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 88622.5781 - val_loss: 87336.4453\n",
      "Epoch 3/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 88622.5781 - val_loss: 87336.4453\n",
      "Epoch 4/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 88622.6094 - val_loss: 87336.4453\n",
      "Epoch 5/20\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 88622.5547 - val_loss: 87336.4453\n",
      "Epoch 6/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 88622.6016 - val_loss: 87336.4453\n",
      "Epoch 7/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 88622.5703 - val_loss: 87336.4453\n",
      "Epoch 8/20\n",
      "563/563 [==============================] - 1s 3ms/step - loss: 88622.5391 - val_loss: 87336.4453\n",
      "Epoch 9/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 88622.5312 - val_loss: 87336.4453\n",
      "Epoch 10/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 88622.5391 - val_loss: 87336.4453\n",
      "Epoch 11/20\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 88622.5938 - val_loss: 87336.4453\n",
      "Epoch 12/20\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 88622.5156 - val_loss: 87336.4453\n",
      "Epoch 13/20\n",
      "563/563 [==============================] - 3s 6ms/step - loss: 88622.6016 - val_loss: 87336.4453\n",
      "Epoch 14/20\n",
      "563/563 [==============================] - 3s 6ms/step - loss: 88622.5547 - val_loss: 87336.4453\n",
      "Epoch 15/20\n",
      "563/563 [==============================] - 3s 6ms/step - loss: 88622.6094 - val_loss: 87336.4453\n",
      "Epoch 16/20\n",
      "563/563 [==============================] - 3s 6ms/step - loss: 88622.5703 - val_loss: 87336.4453\n",
      "Epoch 17/20\n",
      "563/563 [==============================] - 3s 6ms/step - loss: 88622.5547 - val_loss: 87336.4453\n",
      "Epoch 18/20\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 88622.5312 - val_loss: 87336.4453\n",
      "Epoch 19/20\n",
      "563/563 [==============================] - 3s 6ms/step - loss: 88622.5703 - val_loss: 87336.4453\n",
      "Epoch 20/20\n",
      "563/563 [==============================] - 3s 6ms/step - loss: 88622.5703 - val_loss: 87336.4453\n",
      "Epoch 1/20\n",
      "1125/1125 [==============================] - 10s 7ms/step - loss: 65760.8281 - val_loss: 46148.9766\n",
      "Epoch 2/20\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 34771.9727 - val_loss: 23976.4805\n",
      "Epoch 3/20\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 18564.7070 - val_loss: 13314.9199\n",
      "Epoch 4/20\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 10625.3711 - val_loss: 7528.9795\n",
      "Epoch 5/20\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 6464.7324 - val_loss: 5044.1284\n",
      "Epoch 6/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 4731.6431 - val_loss: 4011.5740\n",
      "Epoch 7/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 3898.5320 - val_loss: 3611.7720\n",
      "Epoch 8/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 3519.0408 - val_loss: 3284.8816\n",
      "Epoch 9/20\n",
      "1125/1125 [==============================] - 1s 785us/step - loss: 3330.6406 - val_loss: 3188.5408\n",
      "Epoch 10/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 3199.5342 - val_loss: 3078.6143\n",
      "Epoch 11/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 3105.6514 - val_loss: 3017.3213\n",
      "Epoch 12/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 3036.2556 - val_loss: 2999.6113\n",
      "Epoch 13/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 3002.5476 - val_loss: 2959.0901\n",
      "Epoch 14/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 2937.9927 - val_loss: 2863.7153\n",
      "Epoch 15/20\n",
      "1125/1125 [==============================] - 3s 2ms/step - loss: 2871.9333 - val_loss: 2894.5596\n",
      "Epoch 16/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2837.8821 - val_loss: 2855.2156\n",
      "Epoch 17/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2795.2029 - val_loss: 2750.3057\n",
      "Epoch 18/20\n",
      "1125/1125 [==============================] - 3s 3ms/step - loss: 2757.9226 - val_loss: 2801.4744\n",
      "Epoch 19/20\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 2727.2542 - val_loss: 2751.8027\n",
      "Epoch 20/20\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2710.3035 - val_loss: 2725.7539\n",
      "282/282 [==============================] - 0s 1ms/step\n",
      "282/282 [==============================] - 1s 2ms/step\n",
      "282/282 [==============================] - 1s 2ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "Model: 5\n",
      "Mean Squared Error: 2755.363\n",
      "--------------------\n",
      "Average Mean Squared Error: 2717.3895333333335\n"
     ]
    }
   ],
   "source": [
    "# Model-4: Extract the deep features from Model-I and Model-2 stack the\n",
    "# features horizontally, reduce the dimension to either 8, IO or 12 using\n",
    "# principal component analysis (PCA) and model the reduced features using a\n",
    "# Random Forest classifier. Identify the best number of reduced components of\n",
    "# PCA.\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def model4(X_train, X_val, y_train, y_val):\n",
    "    model_1 = model1(X_train, X_val, y_train, y_val)\n",
    "    model_2, _ = model2(X_train, X_val, y_train, y_val)\n",
    "\n",
    "    intermediate_output1 = model_1.layers[-2].output\n",
    "    intermediate_output2 = model_2.layers[-2].output\n",
    "\n",
    "    intermediate_layer_model_1 = Model(inputs=model_1.input, outputs=intermediate_output1)\n",
    "\n",
    "    intermediate_output1 = intermediate_layer_model_1.predict(X_train)\n",
    "\n",
    "    intermediate_layer_model_2 = Model(inputs=model_2.input, outputs=intermediate_output2)\n",
    "\n",
    "    intermediate_output2 = intermediate_layer_model_2.predict(X_train)\n",
    "\n",
    "    intermediate_output = np.hstack((intermediate_output1, intermediate_output2))\n",
    "\n",
    "    pca = PCA(n_components=8)\n",
    "    pca.fit(intermediate_output)\n",
    "    intermediate_output = pca.transform(intermediate_output)\n",
    "\n",
    "    rf = RandomForestRegressor()\n",
    "    rf.fit(intermediate_output, y_train)\n",
    "\n",
    "    return model_1, model_2, pca, rf\n",
    "\n",
    "count = 5\n",
    "avg_mse = 0\n",
    "\n",
    "for i in range(count):\n",
    "    # Split data to 60% training 20% validation and 20% testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "    model_1, model_2, pca, rf = model4(X_train, X_val, y_train, y_val)\n",
    "\n",
    "    intermediate_output1 = model_1.layers[-2].output\n",
    "    intermediate_output2 = model_2.layers[-2].output\n",
    "\n",
    "    intermediate_layer_model_1 = Model(inputs=model_1.input, outputs=intermediate_output1)\n",
    "    intermediate_output1 = intermediate_layer_model_1.predict(X_test)\n",
    "\n",
    "    intermediate_layer_model_2 = Model(inputs=model_2.input, outputs=intermediate_output2)\n",
    "    intermediate_output2 = intermediate_layer_model_2.predict(X_test)\n",
    "\n",
    "    intermediate_output = np.hstack((intermediate_output1, intermediate_output2))\n",
    "\n",
    "    intermediate_output = pca.transform(intermediate_output)\n",
    "\n",
    "    y_pred = rf.predict(intermediate_output)\n",
    "\n",
    "    print('Model:', i+1)\n",
    "    y_pred = np.round(y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    print('Mean Squared Error:', mse)\n",
    "    print(\"--------------------\")\n",
    "\n",
    "    avg_mse += mse\n",
    "\n",
    "print('Average Mean Squared Error:', avg_mse/count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QNo 5\n",
    "\n",
    "For model1: Average Mean Squared Error: 2823.2824\n",
    "\n",
    "For model2: Average Mean Squared Error: 3557.7468\n",
    "\n",
    "For model3: Average Mean Squared Error: 2942.814533333333\n",
    "\n",
    "For model4: Average Mean Squared Error: 2717.3895333333335\n",
    "\n",
    "so by seeing this avg mean square error we can conclude model 4 is best but when we also consider time to train model 1 is faster"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
